#!/usr/bin/env python3
"""æ–°æµªè´¢ç»å†å²æ•°æ®çˆ¬è™«

æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
1. å†å²æ•°æ®æ¨¡å¼ï¼ˆæŒ‡å®štarget_dateï¼‰ï¼šä½¿ç”¨æ–°æµªè´¢ç»APIè·å–å†å²Kçº¿æ•°æ®ï¼Œæ— éœ€æµè§ˆå™¨
2. å®æ—¶æ•°æ®æ¨¡å¼ï¼ˆä¸æŒ‡å®štarget_dateï¼‰ï¼šä½¿ç”¨Playwrightè®¿é—®é¡µé¢è·å–å®æ—¶æ•°æ®
"""

import asyncio
import sys
import os
import json
import re
import requests
from datetime import datetime
from typing import Dict, List, Optional
from playwright.async_api import async_playwright

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from crawler.sina.market_prefix_helper import get_market_prefix

class SinaHistoryDataFetcher:
    """æ–°æµªè´¢ç»å†å²æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        self.name = "SinaHistoryFetcher"
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        ]

    async def fetch_stock_data(self, page, stock_code: str, target_date: str = None) -> Optional[Dict]:
        """è·å–è‚¡ç¥¨æ•°æ®ï¼ˆæ”¯æŒå½“å¤©å’Œå†å²æ•°æ®ï¼‰"""
        try:
            # ç­‰å¾…é¡µé¢åŠ è½½
            await page.wait_for_load_state("domcontentloaded", timeout=15000)
            await page.wait_for_timeout(2000)
            
            # è·å–é¡µé¢å†…å®¹
            content = await page.content()
            
            # è§£ææ•°æ®
            stock_data = self._parse_sina_data(content, stock_code, target_date)
            return stock_data
            
        except Exception as e:
            print(f"æ–°æµªè´¢ç»æ•°æ®æå–é”™è¯¯ {stock_code}: {e}")
            return None

    def _parse_sina_data(self, html: str, stock_code: str, target_date: str = None) -> Optional[Dict]:
        """è§£ææ–°æµªè´¢ç»HTMLå†…å®¹"""
        data = {
            "code": stock_code,
            "name": None,
            "date": target_date or datetime.now().strftime("%Y-%m-%d"),
            "open": None,
            "high": None,
            "low": None,
            "close": None,
            "volume": None,
            "change": None,
            "change_percent": None,
        }

        # ä»JavaScriptå˜é‡ä¸­æå–æ•°æ®
        patterns = {
            "close": r"var\s+now_price\s*=\s*['\"]([^'\"]*)['\"];",
            "open": r"var\s+open_price\s*=\s*['\"]([^'\"]*)['\"];",
            "high": r"var\s+high_price\s*=\s*['\"]([^'\"]*)['\"];",
            "low": r"var\s+low_price\s*=\s*['\"]([^'\"]*)['\"];",
            "volume": r"var\s+volume\s*=\s*['\"]([^'\"]*)['\"];",
            "name": r"var\s+stockName\s*=\s*['\"]([^'\"]*)['\"];",
            "change": r"var\s+change\s*=\s*['\"]([^'\"]*)['\"];",
            "change_percent": r"var\s+change_percent\s*=\s*['\"]([^'\"]*)['\"];",
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, html)
            if match:
                try:
                    value = match.group(1).strip()
                    if value and value != '':
                        if key == "volume":
                            data[key] = int(float(value.replace(",", "")))
                        elif key in ["change", "change_percent"]:
                            data[key] = float(value.replace("%", ""))
                        elif key == "name":
                            data[key] = value
                        else:
                            data[key] = float(value)
                except (ValueError, AttributeError):
                    continue

        # å¦‚æœæ²¡æœ‰ä»å˜é‡ä¸­è·å–åˆ°closeä»·æ ¼ï¼Œå°è¯•ä»å…¶ä»–æ–¹å¼è·å–
        if data["close"] is None:
            # å°è¯•ä»é¡µé¢æ–‡æœ¬ä¸­æå–ä»·æ ¼
            price_matches = re.findall(r'(\d+\.\d+)', html)
            # è¿‡æ»¤åˆç†çš„ä»·æ ¼èŒƒå›´
            valid_prices = []
            for price_str in price_matches:
                try:
                    price = float(price_str)
                    if 0.1 <= price <= 10000:
                        valid_prices.append(price)
                except ValueError:
                    continue
            
            if valid_prices:
                # é€‰æ‹©æœ€å¯èƒ½çš„å½“å‰ä»·æ ¼
                data["close"] = valid_prices[0] if len(valid_prices) == 1 else valid_prices[1]

        # å¦‚æœæœ‰closeä»·æ ¼ï¼Œè¿”å›æ•°æ®
        if data["close"] is not None:
            return data
        return None

    def fetch_history_data_from_api(self, stock_code: str, target_date: str) -> Optional[Dict]:
        """ä»APIè·å–å†å²æ•°æ®ï¼ˆä¸»è¦æ–¹å¼ï¼‰"""
        try:
            # æ–°æµªè´¢ç»å†å²æ•°æ®API
            market_code = get_market_prefix(stock_code)
            api_url = f"http://money.finance.sina.com.cn/quotes_service/api/json_v2.php/CN_MarketData.getKLineData"
            
            params = {
                'symbol': f'{market_code}{stock_code}',
                'scale': '240',  # æ—¥çº¿
                'ma': 'no',
                'count': '30'  # è·å–æœ€è¿‘30å¤©æ•°æ®
            }
            
            response = requests.get(api_url, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                return self._parse_api_history_data(data, target_date)
            else:
                print(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"æ–°æµªè´¢ç»APIè·å–å†å²æ•°æ®å¤±è´¥ {stock_code}: {e}")
            
        return None

    def _parse_api_history_data(self, api_data: list, target_date: str) -> Optional[Dict]:
        """è§£æAPIå†å²æ•°æ®"""
        if not api_data:
            return None
            
        target_datetime = datetime.strptime(target_date, "%Y-%m-%d")
        
        for item in api_data:
            try:
                item_date = datetime.strptime(item['day'], "%Y-%m-%d")
                if item_date.date() == target_datetime.date():
                    return {
                        "date": target_date,
                        "open": float(item['open']),
                        "high": float(item['high']),
                        "low": float(item['low']),
                        "close": float(item['close']),
                        "volume": int(item['volume']),
                    }
            except (KeyError, ValueError):
                continue
                
        return None

class SinaStockCrawler:
    """æ–°æµªè´¢ç»è‚¡ç¥¨çˆ¬è™«"""
    
    def __init__(self, db_path: str = None):
        self.fetcher = SinaHistoryDataFetcher()
        self.browser = None
        self.playwright = None
        self.db_path = db_path

    async def init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=True,
            args=[
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-dev-shm-usage",
                "--disable-gpu",
                "--disable-web-security",
            ],
        )

    async def close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()

    def get_sina_url(self, stock_code: str) -> str:
        """è·å–æ–°æµªè´¢ç»è‚¡ç¥¨URL"""
        market_prefix = get_market_prefix(stock_code)
        return f"http://finance.sina.com.cn/realstock/company/{market_prefix}{stock_code}/nc.shtml"

    async def crawl_stock_price(self, stock_code: str, target_date: str = None) -> Optional[Dict]:
        """çˆ¬å–å•ä¸ªè‚¡ç¥¨ä»·æ ¼ï¼ˆä¼˜å…ˆä½¿ç”¨APIè·å–å†å²æ•°æ®ï¼‰"""
        print(f"ğŸ•·ï¸ çˆ¬å–æ–°æµªè´¢ç» {stock_code}")
        
        try:
            # å¦‚æœæŒ‡å®šäº†ç›®æ ‡æ—¥æœŸï¼Œä¼˜å…ˆä½¿ç”¨APIè·å–å†å²æ•°æ®
            if target_date:
                print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {target_date}")
                
                # å°è¯•ä»APIè·å–å†å²æ•°æ®
                data = self.fetcher.fetch_history_data_from_api(stock_code, target_date)
                
                if data:
                    data["code"] = stock_code
                    print(f"âœ… æˆåŠŸä»APIæå– {stock_code}: ä»·æ ¼ {data.get('close')} å…ƒ")
                    return data
                else:
                    print(f"âš ï¸  APIæœªæ‰¾åˆ° {stock_code} åœ¨ {target_date} çš„æ•°æ®")
                    return None
            else:
                # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸï¼Œè·å–å®æ—¶æ•°æ®
                url = self.get_sina_url(stock_code)
                print(f"ğŸ“„ è®¿é—®é¡µé¢: {url}")
                
                page = await self.browser.new_page()
                await page.set_extra_http_headers({
                    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
                })
                
                await page.goto(url, wait_until="domcontentloaded", timeout=20000)
                
                # æå–æ•°æ®
                data = await self.fetcher.fetch_stock_data(page, stock_code)
                
                await page.close()
                
                if data:
                    print(f"âœ… æˆåŠŸæå– {stock_code}: ä»·æ ¼ {data.get('close')} å…ƒ")
                    return data
                else:
                    print(f"âŒ æœªèƒ½æå– {stock_code} çš„æ•°æ®")
                    return None
                
        except Exception as e:
            print(f"âŒ çˆ¬å– {stock_code} å¤±è´¥: {e}")
            return None

    def save_to_database(self, stock_data_list: List[Dict]):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        if not self.db_path or not stock_data_list:
            return
            
        try:
            import sqlite3
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            for data in stock_data_list:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ—¥æœŸçš„æ•°æ®
                cursor.execute(
                    "SELECT COUNT(*) FROM merged_stocks WHERE code = ? AND date = ?",
                    (data["code"], data["date"])
                )
                if cursor.fetchone()[0] > 0:
                    print(f"âš ï¸  {data['code']} {data['date']} æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡")
                    continue
                
                # æ’å…¥æ–°æ•°æ®
                insert_data = (
                    None,  # id
                    datetime.now().strftime("%Y-%m-%d %H:%M:%S"),  # created_at
                    data["code"],
                    data["date"],
                    data.get("open"),
                    data.get("high"),
                    data.get("low"),
                    data.get("close"),
                    data.get("volume"),
                    None,  # amount
                    None,  # outstanding_share
                    None,  # turnover
                    data.get("name"),
                    None,  # ma5
                    None,  # ma10
                    None,  # ma20
                    None,  # rsi6
                    None,  # rsi14
                    data.get("change_percent"),  # pct_change
                )
                
                cursor.execute("""
                    INSERT INTO merged_stocks 
                    (id, created_at, code, date, open, high, low, close, volume, amount, 
                     outstanding_share, turnover, name, ma5, ma10, ma20, rsi6, rsi14, pct_change)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, insert_data)
                
                # æ›´æ–°æ•°æ®çŠ¶æ€
                cursor.execute("""
                    INSERT OR REPLACE INTO data_status 
                    (code, last_updated, record_count, status)
                    VALUES (?, ?, ?, ?)
                """, (data["code"], datetime.now().isoformat(), 1, "success"))
            
            conn.commit()
            conn.close()
            print(f"âœ… æˆåŠŸä¿å­˜ {len(stock_data_list)} æ¡è®°å½•åˆ°æ•°æ®åº“")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")

async def crawl_multiple_stocks(stock_codes: List[str], target_date: str = None, db_path: str = None):
    """æ‰¹é‡çˆ¬å–å¤šä¸ªè‚¡ç¥¨"""
    crawler = SinaStockCrawler(db_path)
    
    try:
        results = []
        
        # å¦‚æœæŒ‡å®šäº†ç›®æ ‡æ—¥æœŸï¼Œä½¿ç”¨APIè·å–å†å²æ•°æ®ï¼ˆä¸éœ€è¦æµè§ˆå™¨ï¼‰
        if target_date:
            print(f"ğŸ“… æ‰¹é‡è·å–å†å²æ•°æ®ï¼Œç›®æ ‡æ—¥æœŸ: {target_date}")
            print(f"ğŸ“Š è®¡åˆ’çˆ¬å– {len(stock_codes)} åªè‚¡ç¥¨")
            
            for i, stock_code in enumerate(stock_codes):
                print(f"\n--- å¤„ç†ç¬¬ {i+1}/{len(stock_codes)} åªè‚¡ç¥¨ ---")
                data = crawler.fetcher.fetch_history_data_from_api(stock_code, target_date)
                if data:
                    data["code"] = stock_code
                    results.append(data)
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                if i < len(stock_codes) - 1:
                    await asyncio.sleep(1)
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸï¼Œè·å–å®æ—¶æ•°æ®ï¼ˆéœ€è¦æµè§ˆå™¨ï¼‰
            print(f"ğŸ“„ æ‰¹é‡è·å–å®æ—¶æ•°æ®")
            print(f"ğŸ“Š è®¡åˆ’çˆ¬å– {len(stock_codes)} åªè‚¡ç¥¨")
            
            await crawler.init_browser()
            
            for i, stock_code in enumerate(stock_codes):
                print(f"\n--- å¤„ç†ç¬¬ {i+1}/{len(stock_codes)} åªè‚¡ç¥¨ ---")
                data = await crawler.crawl_stock_price(stock_code)
                if data:
                    results.append(data)
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                if i < len(stock_codes) - 1:
                    await asyncio.sleep(2)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        if results and db_path:
            crawler.save_to_database(results)
        
        print(f"\nğŸ“Š çˆ¬å–ç»“æœæ±‡æ€»:")
        print(f"æˆåŠŸçˆ¬å–: {len(results)} åªè‚¡ç¥¨")
        for result in results:
            date_info = f" ({result['date']})" if result.get('date') else ""
            print(f"- {result['code']}{date_info}: {result['close']:.2f} å…ƒ")
            
        return len(results)
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡çˆ¬å–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 0
    finally:
        await crawler.close_browser()

async def main():
    """ä¸»å‡½æ•° - æµ‹è¯•æ¨¡å¼"""
    # æ•°æ®åº“è·¯å¾„ï¼ˆå¦‚æœéœ€è¦ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
    db_path = "/Users/riching/work/hywork/db/sqlite/full_a_stock_cache.db"
    
    # æµ‹è¯•è‚¡ç¥¨ä»£ç 
    test_stocks = ["600519", "000001", "002323"]
    
    # æµ‹è¯•å†å²æ•°æ®è·å–ï¼ˆä½¿ç”¨APIï¼‰
    print("="*60)
    print("ğŸ¯ æµ‹è¯•å†å²æ•°æ®è·å–ï¼ˆä½¿ç”¨APIï¼‰:")
    print("="*60)
    history_date = "2026-02-09"
    history_success = await crawl_multiple_stocks(test_stocks, history_date, db_path)
    
    # æµ‹è¯•å®æ—¶æ•°æ®è·å–ï¼ˆä½¿ç”¨æµè§ˆå™¨ï¼‰
    print("\n" + "="*60)
    print("ğŸ¯ æµ‹è¯•å®æ—¶æ•°æ®è·å–ï¼ˆä½¿ç”¨æµè§ˆå™¨ï¼‰:")
    print("="*60)
    today_success = await crawl_multiple_stocks(test_stocks, None, db_path)
    
    print(f"\nğŸ æœ€ç»ˆç»“æœ:")
    print(f"å†å²æ•°æ®: {history_success} åªè‚¡ç¥¨")
    print(f"å®æ—¶æ•°æ®: {today_success} åªè‚¡ç¥¨")
    
    return history_success > 0 or today_success > 0

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)