#!/usr/bin/env python3
"""æ–°æµªè´¢ç»å†å²æ•°æ®çˆ¬è™« - ä»é¡µé¢æå–æ•°æ®ç‰ˆ"""

import asyncio
import sys
import os
import re
from datetime import datetime
from typing import Dict, Optional
from playwright.async_api import async_playwright

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from crawler.sina.market_prefix_helper import get_market_prefix


class SinaPageHistoryFetcher:
    """æ–°æµªè´¢ç»å†å²æ•°æ®è·å–å™¨ - ä»é¡µé¢æå–"""
    
    def __init__(self):
        self.name = "SinaPageHistoryFetcher"
    
    async def fetch_history_data(self, page, stock_code: str, target_date: str) -> Optional[Dict]:
        """ä»é¡µé¢æå–å†å²æ•°æ®"""
        try:
            print(f"  ğŸ” å¼€å§‹æå– {stock_code} åœ¨ {target_date} çš„å†å²æ•°æ®...")
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            await page.wait_for_load_state("domcontentloaded", timeout=15000)
            await page.wait_for_timeout(3000)
            
            # è·å–é¡µé¢å†…å®¹
            content = await page.content()
            
            # æ–¹æ³•1: å°è¯•ä»JavaScriptå˜é‡ä¸­æå–Kçº¿æ•°æ®
            kline_data = self._extract_kline_from_js(content, target_date)
            if kline_data:
                print(f"  âœ… ä»JSå˜é‡ä¸­æå–åˆ°Kçº¿æ•°æ®")
                return kline_data
            
            # æ–¹æ³•2: å°è¯•ä»é¡µé¢æ–‡æœ¬ä¸­æå–ä»·æ ¼ä¿¡æ¯
            price_data = self._extract_price_from_text(content, stock_code)
            if price_data:
                print(f"  âœ… ä»é¡µé¢æ–‡æœ¬ä¸­æå–åˆ°ä»·æ ¼æ•°æ®")
                return price_data
            
            # æ–¹æ³•3: å°è¯•ç‚¹å‡»Kçº¿å›¾è¡¨æŒ‰é’®ï¼Œè·å–å†å²æ•°æ®
            kline_data = await self._extract_kline_from_chart(page, stock_code, target_date)
            if kline_data:
                print(f"  âœ… ä»Kçº¿å›¾è¡¨ä¸­æå–åˆ°æ•°æ®")
                return kline_data
            
            print(f"  âŒ æœªèƒ½æå– {stock_code} åœ¨ {target_date} çš„å†å²æ•°æ®")
            return None
            
        except Exception as e:
            print(f"  âŒ æå–å†å²æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _extract_kline_from_js(self, content: str, target_date: str) -> Optional[Dict]:
        """ä»JavaScriptå˜é‡ä¸­æå–Kçº¿æ•°æ®"""
        try:
            # æŸ¥æ‰¾åŒ…å«Kçº¿æ•°æ®çš„JavaScriptå˜é‡
            patterns = [
                r'var\s+kline_data\s*=\s*(\[[^\]]+\])',
                r'var\s+KlineData\s*=\s*(\[[^\]]+\])',
                r'klineData\s*=\s*(\[[^\]]+\])',
                r'data\s*:\s*(\[[^\]]+\])',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, content)
                if match:
                    try:
                        kline_json = match.group(1)
                        kline_data = eval(kline_json)
                        
                        # æŸ¥æ‰¾ç›®æ ‡æ—¥æœŸçš„æ•°æ®
                        for item in kline_data:
                            if isinstance(item, dict) and 'day' in item:
                                if item['day'] == target_date:
                                    return {
                                        "date": target_date,
                                        "open": float(item.get('open', 0)),
                                        "high": float(item.get('high', 0)),
                                        "low": float(item.get('low', 0)),
                                        "close": float(item.get('close', 0)),
                                        "volume": int(item.get('volume', 0)),
                                    }
                    except Exception as e:
                        continue
            
            return None
            
        except Exception as e:
            return None
    
    def _extract_price_from_text(self, content: str, stock_code: str) -> Optional[Dict]:
        """ä»é¡µé¢æ–‡æœ¬ä¸­æå–ä»·æ ¼ä¿¡æ¯"""
        try:
            data = {
                "code": stock_code,
                "date": datetime.now().strftime("%Y-%m-%d"),
                "open": None,
                "high": None,
                "low": None,
                "close": None,
                "volume": None,
            }
            
            # æå–å½“å‰ä»·æ ¼
            close_match = re.search(r'var\s+now_price\s*=\s*["\']?(\d+\.?\d*)["\']?', content)
            if close_match:
                data["close"] = float(close_match.group(1))
            
            # æå–å¼€ç›˜ä»·
            open_match = re.search(r'var\s+open_price\s*=\s*["\']?(\d+\.?\d*)["\']?', content)
            if open_match:
                data["open"] = float(open_match.group(1))
            
            # æå–æœ€é«˜ä»·
            high_match = re.search(r'var\s+high_price\s*=\s*["\']?(\d+\.?\d*)["\']?', content)
            if high_match:
                data["high"] = float(high_match.group(1))
            
            # æå–æœ€ä½ä»·
            low_match = re.search(r'var\s+low_price\s*=\s*["\']?(\d+\.?\d*)["\']?', content)
            if low_match:
                data["low"] = float(low_match.group(1))
            
            # æå–æˆäº¤é‡
            volume_match = re.search(r'var\s+volume\s*=\s*["\']?(\d+)["\']?', content)
            if volume_match:
                data["volume"] = int(volume_match.group(1))
            
            # å¦‚æœæœ‰æ”¶ç›˜ä»·ï¼Œè¿”å›æ•°æ®
            if data["close"] and data["close"] > 0:
                return data
            
            return None
            
        except Exception as e:
            return None
    
    async def _extract_kline_from_chart(self, page, stock_code: str, target_date: str) -> Optional[Dict]:
        """ä»Kçº¿å›¾è¡¨ä¸­æå–æ•°æ®"""
        try:
            # å°è¯•ç‚¹å‡»Kçº¿å›¾è¡¨æŒ‰é’®
            try:
                # æŸ¥æ‰¾Kçº¿æŒ‰é’®
                kline_button = page.locator('text=æ—¥K').first
                if await kline_button.is_visible():
                    await kline_button.click()
                    await page.wait_for_timeout(2000)
                    
                    # é‡æ–°è·å–é¡µé¢å†…å®¹
                    content = await page.content()
                    
                    # å†æ¬¡å°è¯•ä»JSå˜é‡ä¸­æå–
                    kline_data = self._extract_kline_from_js(content, target_date)
                    if kline_data:
                        return kline_data
            except:
                pass
            
            return None
            
        except Exception as e:
            return None


class SinaStockCrawler:
    """æ–°æµªè´¢ç»è‚¡ç¥¨çˆ¬è™« - ä»é¡µé¢æå–ç‰ˆ"""
    
    def __init__(self, db_path: str = None):
        self.fetcher = SinaPageHistoryFetcher()
        self.browser = None
        self.playwright = None
        self.db_path = db_path
    
    async def init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=True,
            args=[
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-dev-shm-usage",
            ]
        )
    
    async def close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
    
    def get_sina_url(self, stock_code: str) -> str:
        """è·å–æ–°æµªè´¢ç»è‚¡ç¥¨URL"""
        market_prefix = get_market_prefix(stock_code)
        return f"http://finance.sina.com.cn/realstock/company/{market_prefix}{stock_code}/nc.shtml"
    
    async def crawl_stock_price(self, stock_code: str, target_date: str = None) -> Optional[Dict]:
        """çˆ¬å–å•ä¸ªè‚¡ç¥¨ä»·æ ¼ï¼ˆä»é¡µé¢æå–ï¼‰"""
        print(f"ğŸ•·ï¸ çˆ¬å–æ–°æµªè´¢ç» {stock_code}")
        
        try:
            url = self.get_sina_url(stock_code)
            print(f"ğŸ“„ è®¿é—®é¡µé¢: {url}")
            
            page = await self.browser.new_page()
            await page.set_extra_http_headers({
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            })
            
            await page.goto(url, wait_until="domcontentloaded", timeout=20000)
            
            # æå–æ•°æ®
            data = await self.fetcher.fetch_history_data(page, stock_code, target_date)
            
            await page.close()
            
            if data:
                data["code"] = stock_code
                print(f"âœ… æˆåŠŸæå– {stock_code}: ä»·æ ¼ {data.get('close')} å…ƒ")
                return data
            else:
                print(f"âŒ æœªèƒ½æå– {stock_code} çš„æ•°æ®")
                return None
                
        except Exception as e:
            print(f"âŒ çˆ¬å– {stock_code} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None


async def test_page_crawler():
    """æµ‹è¯•ä»é¡µé¢æå–æ•°æ®çš„çˆ¬è™«"""
    db_path = "/Users/riching/work/hywork/db/sqlite/full_a_stock_cache.db"
    test_stocks = ["000001", "600519", "000858"]
    target_date = "2026-02-09"
    
    print("=" * 60)
    print("æµ‹è¯•ä»é¡µé¢æå–æ•°æ®çš„æ–°æµªçˆ¬è™«")
    print("=" * 60)
    print(f"ç›®æ ‡æ—¥æœŸ: {target_date}")
    print(f"æµ‹è¯•è‚¡ç¥¨: {test_stocks}")
    
    crawler = SinaStockCrawler(db_path)
    
    try:
        results = []
        
        await crawler.init_browser()
        
        for i, stock_code in enumerate(test_stocks):
            print(f"\n{'='*60}")
            print(f"æµ‹è¯•ç¬¬ {i+1}/{len(test_stocks)} åªè‚¡ç¥¨: {stock_code}")
            print(f"{'='*60}")
            
            data = await crawler.crawl_stock_price(stock_code, target_date)
            if data:
                results.append(data)
            
            await asyncio.sleep(1)
        
        await crawler.close_browser()
        
        print(f"\n{'='*60}")
        print("æµ‹è¯•ç»“æœæ±‡æ€»:")
        print(f"{'='*60}")
        print(f"æˆåŠŸçˆ¬å–: {len(results)} åªè‚¡ç¥¨")
        for result in results:
            print(f"- {result['code']} ({result['date']}): {result['close']} å…ƒ")
        
        return len(results) > 0
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(test_page_crawler())
    sys.exit(0 if success else 1)
