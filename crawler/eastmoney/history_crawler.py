#!/usr/bin/env python3
"""ä¸œæ–¹è´¢å¯Œå†å²ä»·æ ¼æ•°æ®çˆ¬è™« - ä½¿ç”¨Kçº¿API"""

import asyncio
import sys
import os
import re
import requests
from datetime import datetime
from typing import Dict, List, Optional
from playwright.async_api import async_playwright

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from crawler.sina.market_prefix_helper import get_market_prefix

class EastMoneyHistoryExtractor:
    """ä¸œæ–¹è´¢å¯Œå†å²ä»·æ ¼æ•°æ®æå–å™¨"""
    
    def __init__(self):
        self.name = "EastMoneyHistory"
        self.api_base = "https://push2his.eastmoney.com/api/qt/stock/kline/get"

    async def extract_history_data(self, page, stock_code: str, target_date: str) -> Optional[Dict]:
        """æå–æŒ‡å®šæ—¥æœŸçš„å†å²ä»·æ ¼æ•°æ®"""
        try:
            print(f"ğŸ” å¼€å§‹æå– {stock_code} åœ¨ {target_date} çš„å†å²æ•°æ®...")
            
            # è·å–å¸‚åœºä»£ç 
            market_prefix = get_market_prefix(stock_code)
            market = "1" if market_prefix == "sh" else "0"
            
            # æ„é€ APIè¯·æ±‚
            # å°†æ—¥æœŸæ ¼å¼ä»YYYY-MM-DDè½¬æ¢ä¸ºYYYYMMDD
            beg_date = target_date.replace("-", "")
            end_date = target_date.replace("-", "")
            
            url = f"{self.api_base}?secid={market}.{stock_code}&fields1=f1,f2,f3,f4,f5,f6&fields2=f51,f52,f53,f54,f55,f56,f57,f58&klt=101&fqt=1&beg={beg_date}&end={end_date}"
            
            print(f"  ğŸ“¡ è¯·æ±‚API: {url}")
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                if 'data' in data and 'klines' in data['data']:
                    klines = data['data']['klines']
                    
                    if klines:
                        # è§£æKçº¿æ•°æ®
                        kline = klines[0]
                        parts = kline.split(',')
                        
                        # æ ¼å¼: æ—¥æœŸ,å¼€ç›˜,æ”¶ç›˜,æœ€é«˜,æœ€ä½,æˆäº¤é‡,æˆäº¤é¢,æŒ¯å¹…
                        history_data = {
                            "code": stock_code,
                            "date": target_date,
                            "open": float(parts[1]),
                            "close": float(parts[2]),
                            "high": float(parts[3]),
                            "low": float(parts[4]),
                            "volume": int(parts[5]),
                            "name": data['data'].get('name', None)
                        }
                        
                        print(f"âœ… æˆåŠŸæå–å†å²æ•°æ®: å¼€ç›˜={history_data['open']}, æ”¶ç›˜={history_data['close']}, æœ€é«˜={history_data['high']}, æœ€ä½={history_data['low']}")
                        return history_data
                    else:
                        print(f"âš ï¸  æœªæ‰¾åˆ° {target_date} çš„Kçº¿æ•°æ®")
                        return None
                else:
                    print(f"âš ï¸  APIè¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")
                    return None
            else:
                print(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ æå–å†å²æ•°æ®å¤±è´¥ {stock_code}: {e}")
            return None

class EnhancedEastMoneyCrawler:
    """å¢å¼ºç‰ˆä¸œæ–¹è´¢å¯Œçˆ¬è™«ï¼ˆæ”¯æŒå†å²æ•°æ®ï¼‰"""
    
    def __init__(self):
        self.history_extractor = EastMoneyHistoryExtractor()

    async def crawl_history_price(self, stock_code: str, target_date: str) -> Optional[Dict]:
        """çˆ¬å–æŒ‡å®šæ—¥æœŸçš„å†å²ä»·æ ¼æ•°æ®"""
        print(f"ğŸ•·ï¸ çˆ¬å–ä¸œæ–¹è´¢å¯Œå†å²æ•°æ® {stock_code} ({target_date})")
        
        try:
            # ç›´æ¥ä½¿ç”¨APIè·å–å†å²æ•°æ®ï¼Œä¸éœ€è¦page
            data = await self.history_extractor.extract_history_data(None, stock_code, target_date)
            
            if data:
                print(f"âœ… æˆåŠŸæå–å†å²æ•°æ® {stock_code} ({target_date})")
                return data
            else:
                print(f"âŒ æœªèƒ½æå– {stock_code} åœ¨ {target_date} çš„å†å²æ•°æ®")
                return None
                
        except Exception as e:
            print(f"âŒ çˆ¬å–å†å²æ•°æ®å¤±è´¥ {stock_code}: {e}")
            return None

async def main():
    """æµ‹è¯•å†å²æ•°æ®çˆ¬å–åŠŸèƒ½"""
    crawler = EnhancedEastMoneyCrawler()
    
    try:
        # æµ‹è¯•æ•°æ®
        test_cases = [
            {"stock": "002323", "date": "2026-02-09"},
            {"stock": "000001", "date": "2026-02-08"},
            {"stock": "600519", "date": "2026-02-05"}
        ]
        
        results = []
        for case in test_cases:
            data = await crawler.crawl_history_price(case["stock"], case["date"])
            if data:
                results.append(data)
            await asyncio.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        
        print(f"\nğŸ“Š å†å²æ•°æ®çˆ¬å–ç»“æœ:")
        print(f"æˆåŠŸçˆ¬å–: {len(results)} æ¡å†å²è®°å½•")
        for result in results:
            print(f"- {result['code']} ({result['name']}) {result['date']}:")
            print(f"  å¼€ç›˜: {result.get('open')} æœ€é«˜: {result.get('high')}")
            print(f"  æœ€ä½: {result.get('low')} æ”¶ç›˜: {result.get('close')}")
            
        return len(results) > 0
        
    except Exception as e:
        print(f"âŒ å†å²æ•°æ®çˆ¬è™«æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)