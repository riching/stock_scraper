#!/usr/bin/env python3
"""å¤šçº¿ç¨‹ç”Ÿäº§è€…-æ¶ˆè´¹è€…å®æ—¶æ•°æ®çˆ¬è™«"""

import sys
import os
import threading
import asyncio
import time
from queue import Queue
from datetime import datetime
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from utils.stock_database import StockDatabase
from crawler.sina.sina_history_crawler_fixed import SinaStockCrawler
from crawler.eastmoney.eastmoney_crawler import EastMoneyStockCrawler
from crawler.tencent.tencent_crawler import TencentStockCrawler
from utils.akshare_data import AkshareDataFetcher
from crawler.baostock.baostock_history_crawler import BaostockStockCrawler
from crawler.yahoo_finance.yahoo_finance_history_crawler import YahooFinanceStockCrawler


class WorkerStats:
    """æ¶ˆè´¹è€…ç»Ÿè®¡ä¿¡æ¯"""
    
    def __init__(self, worker_name: str):
        self.worker_name = worker_name
        self.success_count = 0
        self.failure_count = 0
        self.call_count = 0
        self.lock = threading.Lock()
    
    def add_success(self):
        with self.lock:
            self.success_count += 1
            self.call_count += 1
    
    def add_failure(self):
        with self.lock:
            self.failure_count += 1
            self.call_count += 1
    
    def get_failure_rate(self) -> float:
        total = self.success_count + self.failure_count
        if total == 0:
            return 0.0
        return (self.failure_count / total) * 100
    
    def get_summary(self) -> Dict:
        return {
            "worker_name": self.worker_name,
            "success": self.success_count,
            "failure": self.failure_count,
            "failure_rate": self.get_failure_rate(),
            "call_count": self.call_count
        }


class BaseWorker(threading.Thread):
    """æ¶ˆè´¹è€…åŸºç±»"""
    
    def __init__(self, queue: Queue, db_path: str, target_date: str, max_calls: int = 5000, test_mode: bool = False):
        super().__init__()
        self.queue = queue
        self.db_path = db_path
        self.target_date = target_date
        self.max_calls = max_calls
        self.test_mode = test_mode
        self.stats = WorkerStats(self.__class__.__name__)
        self.running = True
        self.crawler = None
    
    def run(self):
        """çº¿ç¨‹ä¸»å¾ªç¯"""
        print(f"ğŸš€ {self.__class__.__name__} å¯åŠ¨")
        
        try:
            self.init_crawler()
            
            with StockDatabase(self.db_path) as db:
                while self.running and self.stats.call_count < self.max_calls:
                    try:
                        if self.queue.empty():
                            print(f"â¸ï¸  {self.__class__.__name__}: é˜Ÿåˆ—ä¸ºç©ºï¼Œç­‰å¾…ä»»åŠ¡...")
                            break
                        
                        stock_code = self.queue.get(timeout=5)
                        
                        if stock_code is None:
                            print(f"ğŸ›‘ {self.__class__.__name__}: æ”¶åˆ°ç»ˆæ­¢ä¿¡å·")
                            break
                        
                        print(f"ğŸ”„ {self.__class__.__name__} å¤„ç† {stock_code}")
                        
                        data = self.crawl_stock(stock_code)
                        
                        if self.validate_data(data):
                            if self.test_mode:
                                # æµ‹è¯•æ¨¡å¼ï¼šå¯¹æ¯”æ•°æ®åº“ä¸­çš„æ•°æ®
                                db_data = self.get_db_data(db, stock_code)
                                if self.compare_data(data, db_data):
                                    self.stats.add_success()
                                    print(f"âœ… {self.__class__.__name__} æ•°æ®ä¸€è‡´ {stock_code}")
                                else:
                                    self.stats.add_failure()
                                    print(f"âŒ {self.__class__.__name__} æ•°æ®ä¸ä¸€è‡´ {stock_code}")
                            else:
                                # æ­£å¸¸æ¨¡å¼ï¼šä¿å­˜åˆ°æ•°æ®åº“
                                if self.save_to_database(db, data):
                                    self.stats.add_success()
                                    print(f"âœ… {self.__class__.__name__} æˆåŠŸçˆ¬å– {stock_code}")
                                else:
                                    self.stats.add_failure()
                                    print(f"âŒ {self.__class__.__name__} ä¿å­˜ {stock_code} å¤±è´¥")
                        else:
                            self.stats.add_failure()
                            print(f"âŒ {self.__class__.__name__} æ•°æ®æ— æ•ˆ {stock_code}")
                        
                        self.queue.task_done()
                        
                        # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                        time.sleep(0.5)
                        
                    except Queue.Empty:
                        print(f"â¸ï¸  {self.__class__.__name__}: ä»»åŠ¡é˜Ÿåˆ—è¶…æ—¶")
                        break
                    except Exception as e:
                        self.stats.add_failure()
                        print(f"âŒ {self.__class__.__name__} å¤„ç† {stock_code} å¼‚å¸¸: {e}")
                        self.queue.task_done()
                        time.sleep(1)
        finally:
            self.stop()
    
    def get_db_data(self, db: StockDatabase, stock_code: str) -> Optional[Dict]:
        """ä»æ•°æ®åº“è·å–æ•°æ®"""
        try:
            data = db.get_stock_data(stock_code, self.target_date)
            if data:
                return {
                    "open": data.get("open"),
                    "high": data.get("high"),
                    "low": data.get("low"),
                    "close": data.get("close"),
                    "volume": data.get("volume")
                }
            return None
        except Exception as e:
            print(f"âŒ è·å–æ•°æ®åº“æ•°æ®å¤±è´¥: {e}")
            return None
    
    def compare_data(self, crawl_data: Dict, db_data: Optional[Dict]) -> bool:
        """å¯¹æ¯”çˆ¬å–çš„æ•°æ®å’Œæ•°æ®åº“æ•°æ®"""
        if not db_data:
            print(f"âš ï¸  æ•°æ®åº“ä¸­æ²¡æœ‰ {crawl_data['code']} åœ¨ {self.target_date} çš„æ•°æ®")
            return False
        
        # å¯¹æ¯”ä»·æ ¼æ•°æ®
        for field in ["open", "high", "low", "close"]:
            crawl_value = crawl_data.get(field)
            db_value = db_data.get(field)
            
            if crawl_value is None or db_value is None:
                print(f"âš ï¸  {field} æ•°æ®ç¼ºå¤±: çˆ¬å–={crawl_value}, æ•°æ®åº“={db_value}")
                return False
            
            # å…è®¸å°æ•°ç‚¹è¯¯å·®
            if abs(crawl_value - db_value) > 0.01:
                print(f"âš ï¸  {field} æ•°æ®ä¸ä¸€è‡´: çˆ¬å–={crawl_value}, æ•°æ®åº“={db_value}")
                return False
        
        return True
    
    def init_crawler(self):
        """åˆå§‹åŒ–çˆ¬è™«"""
        pass
    
    def crawl_stock(self, stock_code: str) -> Optional[Dict]:
        """çˆ¬å–è‚¡ç¥¨æ•°æ®"""
        raise NotImplementedError
    
    def validate_data(self, data: Optional[Dict]) -> bool:
        """éªŒè¯æ•°æ®"""
        if not data:
            return False
        if not data.get('close'):
            return False
        if data.get('close') <= 0:
            return False
        return True
    
    def save_to_database(self, db: StockDatabase, data: Dict) -> bool:
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        try:
            # æ£€æŸ¥æ•°æ®æ˜¯å¦å·²å­˜åœ¨
            if db.is_data_exists(data['code'], data['date']):
                print(f"âš ï¸  {data['code']} {data['date']} æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡")
                return True
            
            # æ’å…¥æ•°æ®
            if db.insert_stock_data(data):
                # æ›´æ–°æ•°æ®çŠ¶æ€
                db.update_data_status(data['code'], "success")
                return True
            return False
        except Exception as e:
            print(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            return False
    
    def stop(self):
        """åœæ­¢çº¿ç¨‹"""
        self.running = False
        if hasattr(self, 'crawler') and self.crawler:
            try:
                if hasattr(self.crawler, 'close'):
                    asyncio.run(self.crawler.close())
                elif hasattr(self.crawler, 'close_browser'):
                    asyncio.run(self.crawler.close_browser())
                print(f"âœ… {self.__class__.__name__} å·²å…³é—­")
            except Exception as e:
                print(f"âŒ {self.__class__.__name__} å…³é—­å¤±è´¥: {e}")


class SinaWorker(BaseWorker):
    """æ–°æµªè´¢ç»çˆ¬è™«çº¿ç¨‹"""
    
    def init_crawler(self):
        """åˆå§‹åŒ–æ–°æµªçˆ¬è™«"""
        try:
            self.crawler = SinaStockCrawler(self.db_path)
            print("âœ… æ–°æµªè´¢ç»çˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ–°æµªè´¢ç»çˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
            self.running = False
    
    def crawl_stock(self, stock_code: str) -> Optional[Dict]:
        """çˆ¬å–æ–°æµªè´¢ç»æ•°æ®"""
        try:
            print(f"ğŸ•·ï¸  çˆ¬å–æ–°æµªè´¢ç» {stock_code}")
            # ä½¿ç”¨ç›®æ ‡æ—¥æœŸ
            data = asyncio.run(self.crawler.crawl_stock_price(stock_code, self.target_date))
            return data
        except Exception as e:
            print(f"âŒ æ–°æµªè´¢ç»çˆ¬è™«çˆ¬å– {stock_code} å¤±è´¥: {e}")
            return None


class TencentWorker(BaseWorker):
    """è…¾è®¯è´¢ç»çˆ¬è™«çº¿ç¨‹"""
    
    def init_crawler(self):
        """åˆå§‹åŒ–è…¾è®¯çˆ¬è™«"""
        try:
            self.crawler = TencentStockCrawler(self.db_path)
            print("âœ… è…¾è®¯è´¢ç»çˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ è…¾è®¯è´¢ç»çˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
            self.running = False
    
    def crawl_stock(self, stock_code: str) -> Optional[Dict]:
        """çˆ¬å–è…¾è®¯è´¢ç»æ•°æ®"""
        try:
            print(f"ğŸ•·ï¸  çˆ¬å–è…¾è®¯è´¢ç» {stock_code}")
            # ä½¿ç”¨ç›®æ ‡æ—¥æœŸ
            return asyncio.run(self.crawler.crawl_stock_price(stock_code, self.target_date))
        except Exception as e:
            print(f"âŒ è…¾è®¯è´¢ç»çˆ¬è™«çˆ¬å– {stock_code} å¤±è´¥: {e}")
            return None


class EastMoneyWorker(BaseWorker):
    """ä¸œæ–¹è´¢å¯Œçˆ¬è™«çº¿ç¨‹"""
    
    def init_crawler(self):
        """åˆå§‹åŒ–ä¸œæ–¹è´¢å¯Œçˆ¬è™«"""
        try:
            self.crawler = EastMoneyStockCrawler(self.db_path)
            asyncio.run(self.crawler.init_browser())
            print("âœ… ä¸œæ–¹è´¢å¯Œçˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ä¸œæ–¹è´¢å¯Œçˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
            self.running = False
    
    def crawl_stock(self, stock_code: str) -> Optional[Dict]:
        """çˆ¬å–ä¸œæ–¹è´¢å¯Œæ•°æ®"""
        try:
            print(f"ğŸ•·ï¸  çˆ¬å–ä¸œæ–¹è´¢å¯Œ {stock_code}")
            return asyncio.run(self.crawler.crawl_stock_price(stock_code))
        except Exception as e:
            print(f"âŒ ä¸œæ–¹è´¢å¯Œçˆ¬è™«çˆ¬å– {stock_code} å¤±è´¥: {e}")
            return None


class AkshareWorker(BaseWorker):
    """Akshareçˆ¬è™«çº¿ç¨‹"""
    
    def init_crawler(self):
        """åˆå§‹åŒ–Akshareçˆ¬è™«"""
        try:
            self.crawler = AkshareDataFetcher()
            print("âœ… Akshareçˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Akshareçˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
            self.running = False
    
    def crawl_stock(self, stock_code: str) -> Optional[Dict]:
        """çˆ¬å–Akshareæ•°æ®"""
        try:
            print(f"ğŸ•·ï¸  çˆ¬å–Akshare {stock_code}")
            # ä½¿ç”¨ç›®æ ‡æ—¥æœŸè·å–å†å²æ•°æ®
            data = self.crawler.get_historical_price(stock_code, self.target_date)
            if data:
                return {
                    "code": stock_code,
                    "date": self.target_date,
                    "open": data.get("open"),
                    "high": data.get("high"),
                    "low": data.get("low"),
                    "close": data.get("close"),
                    "volume": data.get("volume"),
                    "name": data.get("name"),
                    "change_percent": data.get("change_percent")
                }
            return None
        except Exception as e:
            print(f"âŒ Akshareçˆ¬è™«çˆ¬å– {stock_code} å¤±è´¥: {e}")
            return None


class BaostockWorker(BaseWorker):
    """Baostockçˆ¬è™«çº¿ç¨‹"""
    
    def init_crawler(self):
        """åˆå§‹åŒ–Baostockçˆ¬è™«"""
        try:
            self.crawler = BaostockStockCrawler(self.db_path)
            print("âœ… Baostockçˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Baostockçˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
            self.running = False
    
    def crawl_stock(self, stock_code: str) -> Optional[Dict]:
        """çˆ¬å–Baostockæ•°æ®"""
        try:
            print(f"ğŸ•·ï¸  çˆ¬å–Baostock {stock_code}")
            # ä½¿ç”¨ç›®æ ‡æ—¥æœŸè·å–å†å²æ•°æ®
            return asyncio.run(self.crawler.crawl_history_price(stock_code, self.target_date))
        except Exception as e:
            print(f"âŒ Baostockçˆ¬è™«çˆ¬å– {stock_code} å¤±è´¥: {e}")
            return None


class YahooFinanceWorker(BaseWorker):
    """Yahoo Financeçˆ¬è™«çº¿ç¨‹"""
    
    def init_crawler(self):
        """åˆå§‹åŒ–Yahoo Financeçˆ¬è™«"""
        try:
            self.crawler = YahooFinanceStockCrawler(self.db_path)
            print("âœ… Yahoo Financeçˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Yahoo Financeçˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
            self.running = False
    
    def crawl_stock(self, stock_code: str) -> Optional[Dict]:
        """çˆ¬å–Yahoo Financeæ•°æ®"""
        try:
            print(f"ğŸ•·ï¸  çˆ¬å–Yahoo Finance {stock_code}")
            # ä½¿ç”¨ç›®æ ‡æ—¥æœŸè·å–å†å²æ•°æ®
            return asyncio.run(self.crawler.crawl_history_price(stock_code, self.target_date))
        except Exception as e:
            print(f"âŒ Yahoo Financeçˆ¬è™«çˆ¬å– {stock_code} å¤±è´¥: {e}")
            return None


class MultiSourceRealTimeCrawler:
    """å¤šçº¿ç¨‹ç”Ÿäº§è€…-æ¶ˆè´¹è€…å®æ—¶æ•°æ®çˆ¬è™«"""
    
    def __init__(self, db_path: str, max_calls: int = 5000, test_mode: bool = False):
        self.db_path = db_path
        self.max_calls = max_calls
        self.test_mode = test_mode
        self.queue = Queue()
        self.workers = []
        self.total_stats = {
            "success": 0,
            "failure": 0,
            "total": 0
        }
    
    def load_stock_codes(self) -> List[str]:
        """åŠ è½½æ‰€æœ‰è‚¡ç¥¨ä»£ç """
        with StockDatabase(self.db_path) as db:
            codes = db.get_all_stock_codes()
            print(f"ğŸ“‹ ä»æ•°æ®åº“åŠ è½½äº† {len(codes)} åªè‚¡ç¥¨")
            return codes
    
    def add_tasks_to_queue(self, stock_codes: List[str]):
        """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        for code in stock_codes:
            self.queue.put(code)
        print(f"ğŸ“‹ é˜Ÿåˆ—ä¸­å…±æœ‰ {self.queue.qsize()} ä¸ªä»»åŠ¡")
    
    def start_workers(self, target_date: str):
        """å¯åŠ¨æ‰€æœ‰æ¶ˆè´¹è€…çº¿ç¨‹"""
        worker_classes = [
            SinaWorker,
            TencentWorker,
            EastMoneyWorker,
            AkshareWorker,
            BaostockWorker,
            YahooFinanceWorker
        ]
        
        for worker_class in worker_classes:
            worker = worker_class(
                self.queue,
                self.db_path,
                target_date,
                self.max_calls,
                self.test_mode
            )
            worker.start()
            self.workers.append(worker)
        
        print(f"ğŸš€ å·²å¯åŠ¨ {len(self.workers)} ä¸ªæ¶ˆè´¹è€…çº¿ç¨‹")
    
    def wait_for_completion(self):
        """ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ"""
        print("â³ ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ...")
        
        # ç­‰å¾…é˜Ÿåˆ—æ¸…ç©º
        self.queue.join()
        
        # å‘é€ç»ˆæ­¢ä¿¡å·
        for _ in self.workers:
            self.queue.put(None)
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
        for worker in self.workers:
            worker.join(timeout=30)
            if worker.is_alive():
                print(f"âš ï¸  {worker.__class__.__name__} çº¿ç¨‹æœªæ­£å¸¸ç»“æŸ")
    
    def collect_stats(self):
        """æ”¶é›†ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“Š çˆ¬è™«ç»Ÿè®¡ä¿¡æ¯")
        print("="*60)
        
        total_success = 0
        total_failure = 0
        
        for worker in self.workers:
            stats = worker.stats.get_summary()
            success = stats["success"]
            failure = stats["failure"]
            total_success += success
            total_failure += failure
            
            total = success + failure
            success_rate = (success / total * 100) if total > 0 else 0
            
            print(f"{stats['worker_name']}:")
            print(f"  æˆåŠŸ: {success}")
            print(f"  å¤±è´¥: {failure}")
            print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
            print()
        
        self.total_stats["success"] = total_success
        self.total_stats["failure"] = total_failure
        self.total_stats["total"] = total_success + total_failure
        
        overall_success_rate = (total_success / self.total_stats["total"] * 100) if self.total_stats["total"] > 0 else 0
        
        print("="*60)
        print("ğŸ“Š æ•´ä½“ç»Ÿè®¡")
        print("="*60)
        print(f"æ€»ä»»åŠ¡æ•°: {self.total_stats['total']}")
        print(f"æˆåŠŸ: {total_success}")
        print(f"å¤±è´¥: {total_failure}")
        print(f"æ•´ä½“æˆåŠŸç‡: {overall_success_rate:.1f}%")
        print("="*60)
    
    def crawl(self, stock_codes: List[str], target_date: str):
        """å¼€å§‹çˆ¬å–"""
        start_time = time.time()
        
        print("="*60)
        print("å¤šçº¿ç¨‹ç”Ÿäº§è€…-æ¶ˆè´¹è€…å®æ—¶æ•°æ®çˆ¬è™«")
        print("="*60)
        print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {target_date}")
        print(f"ğŸ”¢ æœ€å¤§è°ƒç”¨æ¬¡æ•°: {self.max_calls}")
        if self.test_mode:
            print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šä¸å†™æ•°æ®åº“ï¼Œåªå¯¹æ¯”æ•°æ®")
        
        # åŠ è½½è‚¡ç¥¨ä»£ç 
        if not stock_codes:
            stock_codes = self.load_stock_codes()
        
        # æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—
        self.add_tasks_to_queue(stock_codes)
        
        # å¯åŠ¨æ¶ˆè´¹è€…
        self.start_workers(target_date)
        
        # ç­‰å¾…å®Œæˆ
        self.wait_for_completion()
        
        # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
        self.collect_stats()
        
        end_time = time.time()
        print(f"â±ï¸  æ€»è€—æ—¶: {end_time - start_time:.2f}s")
        print("="*60)
        
        return self.total_stats


def main():
    """ä¸»å‡½æ•°"""
    db_path = "/Users/riching/work/hywork/db/sqlite/full_a_stock_cache.db"
    
    # æµ‹è¯•æ¨¡å¼ï¼šåªçˆ¬å–å‡ åªè‚¡ç¥¨
    test_mode = True
    test_count = 10
    
    # è®¾ç½®ç›®æ ‡æ—¥æœŸä¸ºæœ€è¿‘çš„äº¤æ˜“æ—¥ï¼š2026-02-13
    target_date = "2026-02-13"
    
    crawler = MultiSourceRealTimeCrawler(db_path, test_mode=test_mode)
    
    if test_mode:
        # æµ‹è¯•è‚¡ç¥¨
        test_stocks = ["000001", "600519", "000858", "600036", "002323", 
                      "900941", "900943", "900948", "600000", "000002"]
        print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šçˆ¬å– {len(test_stocks)} åªè‚¡ç¥¨")
        print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {target_date}")
        stats = crawler.crawl(test_stocks, target_date)
    else:
        # å…¨é‡çˆ¬å–
        print("ğŸš€ å…¨é‡çˆ¬å–æ¨¡å¼")
        print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {target_date}")
        stats = crawler.crawl([], target_date)
    
    print(f"âœ… çˆ¬å–å®Œæˆï¼æˆåŠŸ: {stats['success']}, å¤±è´¥: {stats['failure']}")


if __name__ == "__main__":
    main()
