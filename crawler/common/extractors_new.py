import asyncio
import time
import random
import re
import json
import aiohttp
from datetime import datetime
from typing import Dict, List, Optional, Any, Union

# Try to import Playwright, but don't fail if not available
try:
    from playwright.async_api import Page
except ImportError:
    Page = Any


class StockDataExtractor:
    """è‚¡ç¥¨æ•°æ®æå–å™¨åŸºç±»"""

    def __init__(self):
        self.name = "BaseExtractor"
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        ]

    async def extract_data(
        self, page: Page, stock_code: str
    ) -> Optional[Dict[str, Any]]:
        """æå–è‚¡ç¥¨æ•°æ®çš„æŠ½è±¡æ–¹æ³•"""
        raise NotImplementedError


class APIStockDataExtractor(StockDataExtractor):
    """åŸºäºAPIçš„è‚¡ç¥¨æ•°æ®æå–å™¨åŸºç±»"""

    def __init__(self):
        super().__init__()
        self.session = None
        self.timeout = 10

    async def get_session(self):
        """è·å–aiohttp session"""
        if self.session is None:
            timeout = aiohttp.ClientTimeout(total=self.timeout)
            self.session = aiohttp.ClientSession(timeout=timeout)
        return self.session

    async def close_session(self):
        """å…³é—­session"""
        if self.session:
            await self.session.close()
            self.session = None

    async def make_api_request(
        self, url: str, headers: Optional[Dict] = None
    ) -> Optional[Dict]:
        """å‘èµ·APIè¯·æ±‚"""
        try:
            session = await self.get_session()
            if headers is None:
                headers = {"User-Agent": random.choice(self.user_agents)}

            async with session.get(url, headers=headers) as response:
                if response.status == 200:
                    content_type = response.headers.get("content-type", "")
                    if "application/json" in content_type:
                        return await response.json()
                    else:
                        # å°è¯•è§£æJSONï¼Œå³ä½¿Content-Typeä¸æ˜¯JSON
                        text = await response.text()
                        try:
                            return json.loads(text)
                        except json.JSONDecodeError:
                            print(f"APIå“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSON: {url}")
                            return None
                else:
                    print(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}, URL: {url}")
                    return None
        except Exception as e:
            print(f"APIè¯·æ±‚å¼‚å¸¸: {e}, URL: {url}")
            return None

    async def extract_data_from_api(self, stock_code: str) -> Optional[Dict[str, Any]]:
        """ä»APIæå–æ•°æ®çš„æŠ½è±¡æ–¹æ³•"""
        raise NotImplementedError


class SinaFinanceExtractor(StockDataExtractor):
    """æ–°æµªè´¢ç»æ•°æ®æå–å™¨"""

    def __init__(self):
        super().__init__()
        self.name = "SinaFinance"

    async def extract_data(self, page: Page, stock_code: str) -> Optional[Dict]:
        try:
            content = await page.content()
            data = self._parse_sina_data(content, stock_code)
            return data

        except Exception as e:
            print(f"SinaFinance extraction error for {stock_code}: {e}")
            return None

    def _parse_sina_data(self, html: str, stock_code: str) -> Optional[Dict]:
        """è§£ææ–°æµªè´¢ç»çš„HTMLå†…å®¹"""
        data = {
            "code": stock_code,
            "name": None,
            "date": datetime.now().strftime("%Y-%m-%d"),
            "open": None,
            "high": None,
            "low": None,
            "close": None,
            "volume": None,
        }

        patterns = {
            "close": r"var now_price\s*=\s*'([^']+)';",
            "open": r"var open_price\s*=\s*'([^']+)';",
            "high": r"var high_price\s*=\s*'([^']+)';",
            "low": r"var low_price\s*=\s*'([^']+)';",
            "volume": r"var volume\s*=\s*'([^']+)';",
            "name": r"var stockName\s*=\s*'([^']+)';",
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, html)
            if match:
                try:
                    value = match.group(1).strip()
                    if key == "volume":
                        data[key] = int(value.replace(",", ""))
                    elif key == "name":
                        data[key] = value
                    else:
                        data[key] = float(value)
                except (ValueError, AttributeError):
                    continue

        if data["close"] is not None:
            return data
        return None


class TencentSecuritiesExtractor(StockDataExtractor):
    """è…¾è®¯è¯åˆ¸æ•°æ®æå–å™¨"""

    def __init__(self):
        super().__init__()
        self.name = "TencentSecurities"

    async def extract_data(self, page: Page, stock_code: str) -> Optional[Dict]:
        try:
            price_selector = ".price, .stock-price, [data-price], .now_price"
            await page.wait_for_selector(price_selector, timeout=8000)

            js_script = """
            () => {
                const data = {};
                const priceSelectors = ['.price', '.stock-price', '[data-price]', '.now_price'];
                for (const selector of priceSelectors) {
                    const element = document.querySelector(selector);
                    if (element) {
                        const text = element.textContent || element.innerText || '';
                        const price = parseFloat(text.replace(/[^0-9.-]/g, ''));
                        if (!isNaN(price)) {
                            data.close = price;
                            break;
                        }
                    }
                }
                const nameElement = document.querySelector('.stock-name, h1, [data-name]');
                if (nameElement) {
                    data.name = nameElement.textContent.trim();
                }
                return data;
            }
            """

            js_data = await page.evaluate(js_script)

            if js_data.get("close"):
                return {
                    "code": stock_code,
                    "name": js_data.get("name"),
                    "date": datetime.now().strftime("%Y-%m-%d"),
                    "close": js_data["close"],
                    "open": None,
                    "high": None,
                    "low": None,
                    "volume": None,
                }
            return None

        except Exception as e:
            print(f"TencentSecurities extraction error for {stock_code}: {e}")
            return None


class SinaFinanceNewsExtractor:
    """æ–°æµªè´¢ç»æ–°é—»æå–å™¨"""

    def __init__(self):
        self.name = "SinaFinanceNews"
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        ]

    async def extract_news(self, page: Page, stock_code: str) -> List[Dict]:
        """æå–æ–°æµªè´¢ç»æ–°é—»"""
        try:
            # æ–°æµªè´¢ç»è‚¡ç¥¨æ–°é—»URLæ¨¡å¼
            news_url = f"http://finance.sina.com.cn/stock/relnews/{stock_code}.shtml"
            await page.goto(news_url, wait_until="domcontentloaded", timeout=10000)

            # ç­‰å¾…æ–°é—»åˆ—è¡¨åŠ è½½
            await page.wait_for_selector(".list_001 li", timeout=5000)

            # æå–æ–°é—»åˆ—è¡¨
            news_items = []
            news_elements = await page.query_selector_all(".list_001 li")

            for element in news_elements[:10]:  # é™åˆ¶è·å–å‰10æ¡
                try:
                    title_element = await element.query_selector("a")
                    date_element = await element.query_selector(".time")

                    if title_element:
                        title = await title_element.text_content()
                        href = await title_element.get_attribute("href")

                        if href and title:
                            # è·å–æ–°é—»è¯¦æƒ…
                            detail_page = await page.context.new_page()
                            try:
                                await detail_page.goto(
                                    href, wait_until="domcontentloaded", timeout=8000
                                )

                                # æå–æ–°é—»å†…å®¹
                                content_element = await detail_page.query_selector(
                                    ".article-content"
                                )
                                if content_element:
                                    content = await content_element.text_content()
                                else:
                                    content = ""

                                # æå–å‘å¸ƒæ—¥æœŸ
                                publish_date = datetime.now().strftime("%Y-%m-%d")
                                if date_element:
                                    date_text = await date_element.text_content()
                                    if date_text:
                                        publish_date = self._parse_date(date_text)

                                news_item = {
                                    "code": stock_code,
                                    "title": title.strip(),
                                    "content": content.strip(),
                                    "source": "SinaFinance",
                                    "publish_date": publish_date,
                                    "url": href,
                                    "fingerprint": self._generate_fingerprint(
                                        title, content, "SinaFinance"
                                    ),
                                }
                                news_items.append(news_item)

                            except Exception as e:
                                print(
                                    f"Error extracting news detail for {stock_code}: {e}"
                                )
                            finally:
                                await detail_page.close()

                except Exception as e:
                    print(f"Error extracting news item for {stock_code}: {e}")
                    continue

            return news_items

        except Exception as e:
            print(f"SinaFinance news extraction error for {stock_code}: {e}")
            return []

    def _generate_fingerprint(self, title: str, content: str, source: str) -> str:
        """ç”Ÿæˆå†…å®¹æŒ‡çº¹"""
        from utils import safe_md5

        fingerprint_input = f"{title.strip()}|{content[:500].strip()}|{source}"
        return safe_md5(fingerprint_input)

    def _parse_date(self, date_str: str) -> str:
        """è§£ææ—¥æœŸå­—ç¬¦ä¸²"""
        # ç®€å•çš„æ—¥æœŸè§£æï¼Œå®é™…é¡¹ç›®ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
        try:
            if "-" in date_str:
                parts = date_str.split("-")
                if len(parts) >= 3:
                    return f"{parts[0]}-{parts[1].zfill(2)}-{parts[2].zfill(2)}"
            return datetime.now().strftime("%Y-%m-%d")
        except:
            return datetime.now().strftime("%Y-%m-%d")


class TonghuashunNewsExtractor(APIStockDataExtractor):
    """åŒèŠ±é¡ºæ–°é—»æå–å™¨ï¼ˆåŸºäºAPIï¼‰"""

    def __init__(self):
        super().__init__()
        self.name = "TonghuashunNews"

    async def extract_news(self, stock_code: str) -> List[Dict]:
        """æå–åŒèŠ±é¡ºæ–°é—»"""
        try:
            # åŒèŠ±é¡ºæ–°é—»APIï¼ˆæ¨¡æ‹Ÿï¼Œå®é™…å¯èƒ½éœ€è¦tokenï¼‰
            # ç”±äºåŒèŠ±é¡ºçš„APIé€šå¸¸éœ€è¦è®¤è¯ï¼Œæˆ‘ä»¬ä½¿ç”¨ç½‘é¡µçˆ¬å–ä½œä¸ºå¤‡é€‰
            market_prefix = "sh" if stock_code.startswith(("6", "9")) else "sz"
            news_url = (
                f"http://news.10jqka.com.cn/tapple/s/{market_prefix}{stock_code}/"
            )

            print(f"ğŸ“¡ è¯·æ±‚åŒèŠ±é¡ºæ–°é—»é¡µé¢: {news_url}")
            response_data = await self.make_api_request(news_url)

            if not response_data:
                # å°è¯•ç›´æ¥è§£æHTMLå†…å®¹
                import aiohttp

                session = await self.get_session()
                async with session.get(
                    news_url, headers={"User-Agent": random.choice(self.user_agents)}
                ) as response:
                    if response.status == 200:
                        html_content = await response.text()
                        # ç®€å•çš„HTMLè§£æ
                        news_items = self._parse_tonghuashun_news_html(
                            html_content, stock_code
                        )
                        return news_items

            return []

        except Exception as e:
            print(f"âŒ åŒèŠ±é¡ºæ–°é—»æå–å¤±è´¥ {stock_code}: {e}")
            return []

    def _parse_tonghuashun_news_html(self, html: str, stock_code: str) -> List[Dict]:
        """è§£æåŒèŠ±é¡ºæ–°é—»HTML"""
        try:
            import re

            news_items = []

            # ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ–°é—»æ ‡é¢˜å’Œé“¾æ¥
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…HTMLç»“æ„è°ƒæ•´
            title_pattern = (
                r'<a[^>]*href="([^"]*news\.10jqka\.com\.cn[^"]*)"[^>]*>([^<]+)</a>'
            )
            matches = re.findall(title_pattern, html, re.IGNORECASE)

            for href, title in matches[:10]:
                news_item = {
                    "code": stock_code,
                    "title": title.strip(),
                    "content": "",  # éœ€è¦å•ç‹¬è¯·æ±‚è¯¦æƒ…é¡µ
                    "source": "Tonghuashun",
                    "publish_date": datetime.now().strftime("%Y-%m-%d"),
                    "url": href,
                    "fingerprint": self._generate_fingerprint(title, "", "Tonghuashun"),
                }
                news_items.append(news_item)

            return news_items
        except Exception as e:
            print(f"è§£æåŒèŠ±é¡ºæ–°é—»HTMLå¤±è´¥: {e}")
            return []

    def _generate_fingerprint(self, title: str, content: str, source: str) -> str:
        """ç”Ÿæˆå†…å®¹æŒ‡çº¹"""
        from utils import safe_md5

        fingerprint_input = f"{title.strip()}|{content[:500].strip()}|{source}"
        return safe_md5(fingerprint_input)


class XueqiuNewsExtractor:
    """é›ªçƒæ–°é—»æå–å™¨ï¼ˆåŸºäºPlaywrightï¼‰"""

    def __init__(self):
        self.name = "XueqiuNews"
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        ]

    async def extract_news(self, page, stock_code: str) -> List[Dict]:
        """æå–é›ªçƒæ–°é—»ï¼ˆä½¿ç”¨Playwrighté¡µé¢ï¼‰"""
        try:
            # é›ªçƒè‚¡ç¥¨ä»£ç éœ€è¦æ·»åŠ å¸‚åœºå‰ç¼€
            market_prefix = "SH" if stock_code.startswith(("6", "9")) else "SZ"
            symbol = f"{market_prefix}{stock_code}"

            # è®¿é—®é›ªçƒè‚¡ç¥¨é¡µé¢
            await page.goto(
                f"https://xueqiu.com/S/{symbol}",
                wait_until="networkidle",
                timeout=15000,
            )

            # æå–åŠ¨æ€å†…å®¹
            news_items = []
            timeline_items = await page.query_selector_all(".timeline-item")

            for item in timeline_items[:10]:
                try:
                    # å°è¯•å¤šç§é€‰æ‹©å™¨è·å–æ ‡é¢˜å’Œå†…å®¹
                    title = ""
                    content = ""

                    # å°è¯•è·å–æ ‡é¢˜
                    title_element = await item.query_selector(".title a")
                    if title_element:
                        title = await title_element.text_content()

                    # å°è¯•è·å–å†…å®¹
                    content_element = await item.query_selector(".content .text")
                    if not content_element:
                        content_element = await item.query_selector(".content")
                    if content_element:
                        content = await content_element.text_content()

                    # å¦‚æœæ²¡æœ‰æ ‡é¢˜ï¼Œå°è¯•ä»å†…å®¹ä¸­æå–
                    if not title and content:
                        title = content[:50] + "..." if len(content) > 50 else content

                    if title and len(title.strip()) > 10:
                        news_item = {
                            "code": stock_code,
                            "title": title.strip(),
                            "content": content.strip(),
                            "source": "Xueqiu",
                            "publish_date": datetime.now().strftime("%Y-%m-%d"),
                            "url": f"https://xueqiu.com/S/{symbol}",
                            "fingerprint": self._generate_fingerprint(
                                title, content, "Xueqiu"
                            ),
                        }
                        news_items.append(news_item)

                except Exception as e:
                    print(f"Error processing Xueqiu news item: {e}")
                    continue

            print(f"âœ… é›ªçƒæ–°é—»æå–æˆåŠŸ: {len(news_items)} æ¡")
            return news_items

        except Exception as e:
            print(f"âŒ é›ªçƒæ–°é—»æå–å¤±è´¥ {stock_code}: {e}")
            return []

    def _generate_fingerprint(self, title: str, content: str, source: str) -> str:
        """ç”Ÿæˆå†…å®¹æŒ‡çº¹"""
        from utils import safe_md5

        fingerprint_input = f"{title.strip()}|{content[:500].strip()}|{source}"
        return safe_md5(fingerprint_input)


class XueqiuCommentExtractor:
    """é›ªçƒè¯„è®ºæå–å™¨ï¼ˆåŸºäºPlaywrightï¼‰"""

    def __init__(self):
        self.name = "XueqiuComment"
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        ]

    async def extract_comments(self, page, stock_code: str) -> List[Dict]:
        """æå–é›ªçƒè¯„è®ºï¼ˆä½¿ç”¨Playwrighté¡µé¢ï¼‰"""
        try:
            # é›ªçƒè‚¡ç¥¨ä»£ç éœ€è¦æ·»åŠ å¸‚åœºå‰ç¼€
            market_prefix = "SH" if stock_code.startswith(("6", "9")) else "SZ"
            symbol = f"{market_prefix}{stock_code}"

            # è®¿é—®é›ªçƒè‚¡ç¥¨é¡µé¢
            await page.goto(
                f"https://xueqiu.com/S/{symbol}",
                wait_until="networkidle",
                timeout=15000,
            )

            # æå–è¯„è®º
            comments = []
            comment_items = await page.query_selector_all(".comment-item")

            for item in comment_items[:10]:
                try:
                    # æå–è¯„è®ºå†…å®¹
                    content_element = await item.query_selector(".content .text")
                    if not content_element:
                        content_element = await item.query_selector(".content")

                    content = ""
                    if content_element:
                        content = await content_element.text_content()

                    # æå–ä½œè€…
                    author_element = await item.query_selector(".user-info .name")
                    author = ""
                    if author_element:
                        author = await author_element.text_content()

                    # æå–ç‚¹èµæ•°
                    likes_element = await item.query_selector(".like-count")
                    likes = 0
                    if likes_element:
                        likes_text = await likes_element.text_content()
                        try:
                            likes = int(likes_text)
                        except:
                            likes = 0

                    if content and len(content.strip()) > 10:
                        comment_item = {
                            "code": stock_code,
                            "content": content.strip(),
                            "author": author.strip() if author else "åŒ¿å",
                            "platform": "Xueqiu",
                            "publish_date": datetime.now().strftime("%Y-%m-%d"),
                            "url": f"https://xueqiu.com/S/{symbol}",
                            "likes": likes,
                            "fingerprint": self._generate_fingerprint(
                                content, author, "Xueqiu"
                            ),
                        }
                        comments.append(comment_item)

                except Exception as e:
                    print(f"Error processing Xueqiu comment item: {e}")
                    continue

            print(f"âœ… é›ªçƒè¯„è®ºæå–æˆåŠŸ: {len(comments)} æ¡")
            return comments

        except Exception as e:
            print(f"âŒ é›ªçƒè¯„è®ºæå–å¤±è´¥ {stock_code}: {e}")
            return []

    def _generate_fingerprint(self, content: str, author: str, source: str) -> str:
        """ç”Ÿæˆå†…å®¹æŒ‡çº¹"""
        from utils import safe_md5

        fingerprint_input = f"{content.strip()}|{author.strip()}|{source}"
        return safe_md5(fingerprint_input)


class TonghuashunAnnouncementExtractor(APIStockDataExtractor):
    """åŒèŠ±é¡ºå…¬å‘Šæå–å™¨ï¼ˆåŸºäºAPIï¼‰"""

    def __init__(self):
        super().__init__()
        self.name = "TonghuashunAnnouncement"

    async def extract_announcements(self, stock_code: str) -> List[Dict]:
        """æå–åŒèŠ±é¡ºå…¬å‘Š"""
        try:
            # åŒèŠ±é¡ºå…¬å‘Šé¡µé¢
            announcement_url = (
                f"http://basic.10jqka.com.cn/{stock_code}/announcement.html"
            )

            print(f"ğŸ“¡ è¯·æ±‚åŒèŠ±é¡ºå…¬å‘Šé¡µé¢: {announcement_url}")
            import aiohttp

            session = await self.get_session()
            async with session.get(
                announcement_url,
                headers={"User-Agent": random.choice(self.user_agents)},
            ) as response:
                if response.status == 200:
                    html_content = await response.text()
                    announcements = self._parse_tonghuashun_announcements_html(
                        html_content, stock_code
                    )
                    return announcements

            return []

        except Exception as e:
            print(f"âŒ åŒèŠ±é¡ºå…¬å‘Šæå–å¤±è´¥ {stock_code}: {e}")
            return []

    def _parse_tonghuashun_announcements_html(
        self, html: str, stock_code: str
    ) -> List[Dict]:
        """è§£æåŒèŠ±é¡ºå…¬å‘ŠHTML"""
        try:
            import re

            announcements = []

            # ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å…¬å‘Š
            # å®é™…å®ç°éœ€è¦æ ¹æ®å…·ä½“HTMLç»“æ„è°ƒæ•´
            pattern = (
                r'<a[^>]*href="([^"]*basic\.10jqka\.com\.cn[^"]*)"[^>]*>([^<]+)</a>'
            )
            matches = re.findall(pattern, html, re.IGNORECASE)

            for href, title in matches[:10]:
                announcement_item = {
                    "code": stock_code,
                    "title": title.strip(),
                    "content": "",
                    "announcement_type": "å…¬å‘Š",
                    "publish_date": datetime.now().strftime("%Y-%m-%d"),
                    "url": href,
                    "fingerprint": self._generate_fingerprint(title, "", "Tonghuashun"),
                }
                announcements.append(announcement_item)

            return announcements
        except Exception as e:
            print(f"è§£æåŒèŠ±é¡ºå…¬å‘ŠHTMLå¤±è´¥: {e}")
            return []

    def _generate_fingerprint(self, title: str, content: str, source: str) -> str:
        """ç”Ÿæˆå†…å®¹æŒ‡çº¹"""
        from utils import safe_md5

        fingerprint_input = f"{title.strip()}|{content[:500].strip()}|{source}"
        return safe_md5(fingerprint_input)

    def _parse_date(self, date_str: str) -> str:
        """è§£ææ—¥æœŸå­—ç¬¦ä¸²"""
        try:
            if "-" in date_str:
                parts = date_str.split("-")
                if len(parts) >= 3:
                    return f"{parts[0]}-{parts[1].zfill(2)}-{parts[2].zfill(2)}"
            return datetime.now().strftime("%Y-%m-%d")
        except:
            return datetime.now().strftime("%Y-%m-%d")


class EastMoneyAnnouncementExtractor(APIStockDataExtractor):
    """ä¸œæ–¹è´¢å¯Œå…¬å‘Šæå–å™¨ï¼ˆåŸºäºAPIï¼‰"""

    def __init__(self):
        super().__init__()
        self.name = "EastMoneyAnnouncement"

    async def extract_announcements(self, stock_code: str) -> List[Dict]:
        """æå–ä¸œæ–¹è´¢å¯Œå…¬å‘Š"""
        try:
            # æ„é€ ä¸œæ–¹è´¢å¯Œå…¬å‘ŠAPI URL
            # ä¸œæ–¹è´¢å¯Œå…¬å‘ŠAPIé€šå¸¸éœ€è¦é€šè¿‡æœç´¢æ¥å£
            market_code = "1" if stock_code.startswith(("6", "9")) else "0"
            api_url = f"https://datacenter.eastmoney.com/api/data/v1/get?callback=&sortColumns=NOTICEDATE&sortTypes=-1&pageSize=20&pageNumber=1&reportName=RPT_ANNOUNCEMENT_RESEARCH&columns=ALL&filter=(SECURITY_CODE%3D%22{stock_code}%22)"

            print(f"ğŸ“¡ è¯·æ±‚ä¸œæ–¹è´¢å¯Œå…¬å‘ŠAPI: {api_url}")
            response_data = await self.make_api_request(api_url)

            if not response_data:
                print(f"âš ï¸  ä¸œæ–¹è´¢å¯Œå…¬å‘ŠAPIè¿”å›ç©ºæ•°æ®: {stock_code}")
                return []

            # è§£æAPIå“åº”
            announcements = []
            if isinstance(response_data, dict) and "result" in response_data:
                result = response_data["result"]
                if isinstance(result, dict) and "data" in result:
                    announcement_list = result["data"]
                    for item in announcement_list[:10]:  # é™åˆ¶è·å–å‰10æ¡
                        try:
                            title = item.get("NOTICETITLE", "")
                            content = item.get("NOTICECONTENT", "")
                            publish_date = item.get("NOTICEDATE", "")
                            url = item.get("PDF_URL", "")

                            if not url:
                                # æ„é€ å…¬å‘Šè¯¦æƒ…é¡µURL
                                notice_id = item.get("INFO_CODE", "")
                                if notice_id:
                                    url = (
                                        f"https://pdf.dfcfw.com/pdf/H2_{notice_id}.pdf"
                                    )

                            if title and content:
                                # æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼
                                if publish_date:
                                    # ä¸œæ–¹è´¢å¯Œæ—¥æœŸæ ¼å¼é€šå¸¸æ˜¯ "2024-01-15 10:30:00"
                                    publish_date = publish_date.split(" ")[0]
                                else:
                                    publish_date = datetime.now().strftime("%Y-%m-%d")

                                announcement_item = {
                                    "code": stock_code,
                                    "title": title.strip(),
                                    "content": content.strip(),
                                    "announcement_type": item.get("TYPE_NAME", "å…¬å‘Š"),
                                    "publish_date": publish_date,
                                    "url": url,
                                    "fingerprint": self._generate_fingerprint(
                                        title, content, "EastMoney"
                                    ),
                                }
                                announcements.append(announcement_item)

                        except Exception as e:
                            print(f"Error processing EastMoney announcement item: {e}")
                            continue

            print(f"âœ… ä¸œæ–¹è´¢å¯Œå…¬å‘Šæå–æˆåŠŸ: {len(announcements)} æ¡")
            return announcements

        except Exception as e:
            print(f"âŒ ä¸œæ–¹è´¢å¯Œå…¬å‘Šæå–å¤±è´¥ {stock_code}: {e}")
            return []

    def _generate_fingerprint(self, title: str, content: str, source: str) -> str:
        """ç”Ÿæˆå†…å®¹æŒ‡çº¹"""
        from utils import safe_md5

        fingerprint_input = f"{title.strip()}|{content[:500].strip()}|{source}"
        return safe_md5(fingerprint_input)
