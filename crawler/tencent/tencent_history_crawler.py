#!/usr/bin/env python3
"""è…¾è®¯è´¢ç»å†å²æ•°æ®çˆ¬è™« - ä½¿ç”¨APIæ¥å£"""

import asyncio
import sys
import os
import re
import requests
import sqlite3
from datetime import datetime
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from crawler.sina.market_prefix_helper import get_market_prefix

class TencentHistoryDataFetcher:
    """è…¾è®¯è´¢ç»å†å²æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        self.name = "TencentHistoryFetcher"
        self.api_base = "http://web.ifzq.gtimg.cn/appstock/app/fqkline/get"

    async def fetch_history_data(self, stock_code: str, target_date: str) -> Optional[Dict]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„å†å²æ•°æ®"""
        try:
            print(f"ğŸ” å¼€å§‹è·å– {stock_code} åœ¨ {target_date} çš„å†å²æ•°æ®...")
            
            # è·å–å¸‚åœºå‰ç¼€
            market_prefix = get_market_prefix(stock_code)
            
            # æ„é€ API URL
            # å‚æ•°æ ¼å¼: è‚¡ç¥¨ä»£ç ,å‘¨æœŸ,å¼€å§‹æ—¥æœŸ,ç»“æŸæ—¥æœŸ,æ•°é‡,å¤æƒç±»å‹
            # å‘¨æœŸ: day=æ—¥, week=å‘¨, month=æœˆ
            # å¤æƒç±»å‹: qfq=å‰å¤æƒ, hfq=åå¤æƒ, none=ä¸å¤æƒ
            url = f"{self.api_base}?param={stock_code},day,{target_date},{target_date},640,qfq"
            
            print(f"  ğŸ“¡ è¯·æ±‚API: {url}")
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                if 'data' in data and stock_code in data['data']:
                    kline_data = data['data'][stock_code]
                    
                    if kline_data and len(kline_data) > 0:
                        # è§£æKçº¿æ•°æ®
                        # æ ¼å¼: [æ—¥æœŸ,å¼€ç›˜,æ”¶ç›˜,æœ€é«˜,æœ€ä½,æˆäº¤é‡,æˆäº¤é¢,æŒ¯å¹…,æ¶¨è·Œé¢,æ¶¨è·Œå¹…,æ¢æ‰‹ç‡]
                        kline = kline_data[0]
                        
                        history_data = {
                            "code": stock_code,
                            "date": target_date,
                            "open": float(kline[1]) if kline[1] else None,
                            "close": float(kline[2]) if kline[2] else None,
                            "high": float(kline[3]) if kline[3] else None,
                            "low": float(kline[4]) if kline[4] else None,
                            "volume": int(kline[5]) if kline[5] else None,
                            "name": None
                        }
                        
                        print(f"âœ… æˆåŠŸæå–å†å²æ•°æ®: å¼€ç›˜={history_data['open']}, æ”¶ç›˜={history_data['close']}, æœ€é«˜={history_data['high']}, æœ€ä½={history_data['low']}")
                        return history_data
                    else:
                        print(f"âš ï¸  æœªæ‰¾åˆ° {target_date} çš„Kçº¿æ•°æ®ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥ï¼‰")
                        return None
                else:
                    print(f"âš ï¸  APIè¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")
                    return None
            else:
                print(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ è…¾è®¯è´¢ç»å†å²æ•°æ®æå–é”™è¯¯ {stock_code}: {e}")
            return None

class TencentHistoryCrawler:
    """è…¾è®¯è´¢ç»å†å²æ•°æ®çˆ¬è™«ä¸»ç±»"""
    
    def __init__(self, db_path: str = None):
        self.fetcher = TencentHistoryDataFetcher()
        self.db_path = db_path

    async def crawl_history_price(self, stock_code: str, target_date: str) -> Optional[Dict]:
        """çˆ¬å–æŒ‡å®šæ—¥æœŸçš„å†å²ä»·æ ¼"""
        print(f"ğŸ•·ï¸ çˆ¬å–è…¾è®¯è´¢ç»å†å²æ•°æ® {stock_code} ({target_date})")
        
        try:
            # è·å–å†å²æ•°æ®
            data = await self.fetcher.fetch_history_data(stock_code, target_date)
            
            if data:
                print(f"âœ… æˆåŠŸæå–å†å²æ•°æ® {stock_code} ({target_date})")
                return data
            else:
                print(f"âŒ æœªèƒ½æå– {stock_code} åœ¨ {target_date} çš„å†å²æ•°æ®")
                return None
                
        except Exception as e:
            print(f"âŒ çˆ¬å–å†å²æ•°æ®å¤±è´¥ {stock_code}: {e}")
            return None

    def save_to_database(self, stock_data_list: List[Dict]):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        if not self.db_path or not stock_data_list:
            return
            
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            for data in stock_data_list:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ—¥æœŸçš„æ•°æ®
                cursor.execute(
                    "SELECT COUNT(*) FROM merged_stocks WHERE code = ? AND date = ?",
                    (data["code"], data["date"])
                )
                if cursor.fetchone()[0] > 0:
                    print(f"âš ï¸  {data['code']} {data['date']} æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡")
                    continue
                
                # æ’å…¥æ–°æ•°æ®
                insert_data = (
                    None,  # id
                    datetime.now().strftime("%Y-%m-%d %H:%M:%S"),  # created_at
                    data["code"],
                    data["date"],
                    data.get("open"),
                    data.get("high"),
                    data.get("low"),
                    data.get("close"),
                    data.get("volume"),
                    None,  # amount
                    None,  # outstanding_share
                    None,  # turnover
                    data.get("name"),
                    None,  # ma5
                    None,  # ma10
                    None,  # ma20
                    None,  # rsi6
                    None,  # rsi14
                    None,  # pct_change
                )
                
                cursor.execute("""
                    INSERT INTO merged_stocks 
                    (id, created_at, code, date, open, high, low, close, volume, amount, 
                     outstanding_share, turnover, name, ma5, ma10, ma20, rsi6, rsi14, pct_change)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, insert_data)
                
                # æ›´æ–°æ•°æ®çŠ¶æ€
                cursor.execute("""
                    INSERT OR REPLACE INTO data_status 
                    (code, last_updated, record_count, status)
                    VALUES (?, ?, ?, ?)
                """, (data["code"], datetime.now().isoformat(), 1, "success"))
            
            conn.commit()
            conn.close()
            print(f"âœ… æˆåŠŸä¿å­˜ {len(stock_data_list)} æ¡è®°å½•åˆ°æ•°æ®åº“")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")

async def crawl_multiple_history_stocks(stock_codes: List[str], target_date: str, db_path: str = None):
    """æ‰¹é‡çˆ¬å–å¤šä¸ªè‚¡ç¥¨çš„å†å²æ•°æ®"""
    crawler = TencentHistoryCrawler(db_path)
    
    try:
        results = []
        for i, stock_code in enumerate(stock_codes):
            print(f"\n--- å¤„ç†ç¬¬ {i+1}/{len(stock_codes)} åªè‚¡ç¥¨ ---")
            data = await crawler.crawl_history_price(stock_code, target_date)
            if data:
                results.append(data)
            
            # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            if i < len(stock_codes) - 1:
                await asyncio.sleep(0.5)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        if results and db_path:
            crawler.save_to_database(results)
        
        print(f"\nğŸ“Š å†å²æ•°æ®çˆ¬å–ç»“æœæ±‡æ€»:")
        print(f"æˆåŠŸçˆ¬å–: {len(results)} æ¡å†å²è®°å½•")
        for result in results:
            print(f"- {result['code']} ({result['name']}) {result['date']}:")
            print(f"  å¼€ç›˜: {result.get('open')} æœ€é«˜: {result.get('high')}")
            print(f"  æœ€ä½: {result.get('low')} æ”¶ç›˜: {result.get('close')}")
            
        return len(results)
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡çˆ¬å–å¤±è´¥: {e}")
        return 0

async def main():
    """ä¸»å‡½æ•° - æµ‹è¯•æ¨¡å¼"""
    print("=" * 60)
    print("è…¾è®¯è´¢ç»å†å²æ•°æ®çˆ¬è™«æµ‹è¯•")
    print("=" * 60)
    
    # æ•°æ®åº“è·¯å¾„ï¼ˆå¦‚æœéœ€è¦ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
    db_path = "/Users/riching/work/hywork/db/sqlite/full_a_stock_cache.db"
    
    # æµ‹è¯•è‚¡ç¥¨ä»£ç 
    test_stocks = ["000001", "600519", "000858", "600036", "002323"]
    
    # ç›®æ ‡æ—¥æœŸ
    target_date = "2026-02-12"
    
    print(f"ğŸ“ˆ è®¡åˆ’çˆ¬å– {len(test_stocks)} åªè‚¡ç¥¨")
    print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {target_date}")
    print()
    
    success_count = await crawl_multiple_history_stocks(test_stocks, target_date, db_path)
    
    if success_count > 0:
        print(f"\nğŸ‰ æˆåŠŸçˆ¬å– {success_count} åªè‚¡ç¥¨çš„å†å²æ•°æ®ï¼")
        return True
    else:
        print(f"\nâŒ å†å²æ•°æ®çˆ¬å–å¤±è´¥")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
