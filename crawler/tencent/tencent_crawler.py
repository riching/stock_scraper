#!/usr/bin/env python3
"""è…¾è®¯è´¢ç»è‚¡ç¥¨ä»·æ ¼çˆ¬è™« - ä½¿ç”¨APIæ¥å£"""

import asyncio
import sys
import os
import re
import requests
import sqlite3
from datetime import datetime
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from crawler.sina.market_prefix_helper import get_market_prefix

class TencentStockExtractor:
    """è…¾è®¯è´¢ç»è‚¡ç¥¨æ•°æ®æå–å™¨"""
    
    def __init__(self):
        self.name = "TencentFinance"
        self.api_base = "http://qt.gtimg.cn/q="

    async def extract_stock_data(self, stock_code: str) -> Optional[Dict]:
        """æå–è…¾è®¯è´¢ç»è‚¡ç¥¨æ•°æ® - ä½¿ç”¨API"""
        try:
            # è·å–å¸‚åœºå‰ç¼€
            market_prefix = get_market_prefix(stock_code)
            
            # æ„é€ API URL
            url = f"{self.api_base}{market_prefix}{stock_code}"
            
            print(f"  ğŸ“¡ è¯·æ±‚API: {url}")
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                content = response.text
                
                # è§£æAPIè¿”å›çš„æ•°æ®
                # æ ¼å¼: v_sh600519="1~è´µå·èŒ…å°~1485.30~1480.00~1500.00~1480.00~1234567~..."
                data = self._parse_api_data(content, stock_code)
                
                if data:
                    print(f"âœ… æˆåŠŸæå– {stock_code}: ä»·æ ¼ {data['close']} å…ƒ")
                    return data
                else:
                    print(f"âŒ æœªèƒ½è§£æ {stock_code} çš„æ•°æ®")
                    return None
            else:
                print(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ è…¾è®¯è´¢ç»æå–é”™è¯¯ {stock_code}: {e}")
            return None

    def _parse_api_data(self, content: str, stock_code: str) -> Optional[Dict]:
        """è§£æAPIè¿”å›çš„æ•°æ®"""
        try:
            # æŸ¥æ‰¾æ•°æ®è¡Œ
            pattern = rf'v_{get_market_prefix(stock_code)}{stock_code}="([^"]*)"'
            match = re.search(pattern, content)
            
            if match:
                data_str = match.group(1)
                parts = data_str.split('~')
                
                if len(parts) >= 7:
                    # æ•°æ®æ ¼å¼: 1~åç§°~ä»£ç ~å½“å‰ä»·~æ˜¨æ”¶~å¼€ç›˜~æˆäº¤é‡~...
                    data = {
                        "code": parts[2].strip(),
                        "name": parts[1].strip(),
                        "date": datetime.now().strftime("%Y-%m-%d"),
                        "open": float(parts[5]) if parts[5] else None,
                        "high": None,
                        "low": None,
                        "close": float(parts[3]) if parts[3] else None,
                        "volume": int(parts[6]) if parts[6] and parts[6].isdigit() else None,
                        "change": None,
                        "change_percent": None,
                    }
                    
                    # è®¡ç®—æ¶¨è·Œé¢å’Œæ¶¨è·Œå¹…
                    if data["close"] and parts[4]:
                        yesterday_close = float(parts[4])
                        data["change"] = data["close"] - yesterday_close
                        if yesterday_close > 0:
                            data["change_percent"] = ((data["close"] - yesterday_close) / yesterday_close) * 100
                    
                    return data
            
            return None
            
        except Exception as e:
            print(f"è§£æAPIæ•°æ®å¤±è´¥: {e}")
            return None

class TencentStockCrawler:
    """è…¾è®¯è´¢ç»è‚¡ç¥¨çˆ¬è™«ä¸»ç±»"""
    
    def __init__(self, db_path: str = None):
        self.extractor = TencentStockExtractor()
        self.db_path = db_path

    async def crawl_stock_price(self, stock_code: str, target_date: str = None) -> Optional[Dict]:
        """çˆ¬å–å•ä¸ªè‚¡ç¥¨ä»·æ ¼"""
        print(f"ğŸ•·ï¸ çˆ¬å–è…¾è®¯è´¢ç» {stock_code}")
        
        try:
            # æå–æ•°æ®
            data = await self.extractor.extract_stock_data(stock_code)
            
            if data:
                # è®¾ç½®ç›®æ ‡æ—¥æœŸ
                if target_date:
                    data["date"] = target_date
                return data
            else:
                return None
                
        except Exception as e:
            print(f"âŒ çˆ¬å– {stock_code} å¤±è´¥: {e}")
            return None

    def save_to_database(self, stock_data_list: List[Dict]):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        if not self.db_path or not stock_data_list:
            return
            
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            for data in stock_data_list:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ—¥æœŸçš„æ•°æ®
                cursor.execute(
                    "SELECT COUNT(*) FROM merged_stocks WHERE code = ? AND date = ?",
                    (data["code"], data["date"])
                )
                if cursor.fetchone()[0] > 0:
                    print(f"âš ï¸  {data['code']} {data['date']} æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡")
                    continue
                
                # æ’å…¥æ–°æ•°æ®
                insert_data = (
                    None,  # id
                    datetime.now().strftime("%Y-%m-%d %H:%M:%S"),  # created_at
                    data["code"],
                    data["date"],
                    data.get("open"),
                    data.get("high"),
                    data.get("low"),
                    data.get("close"),
                    data.get("volume"),
                    None,  # amount
                    None,  # outstanding_share
                    None,  # turnover
                    data.get("name"),
                    None,  # ma5
                    None,  # ma10
                    None,  # ma20
                    None,  # rsi6
                    None,  # rsi14
                    data.get("change_percent"),  # pct_change
                )
                
                cursor.execute("""
                    INSERT INTO merged_stocks 
                    (id, created_at, code, date, open, high, low, close, volume, amount, 
                     outstanding_share, turnover, name, ma5, ma10, ma20, rsi6, rsi14, pct_change)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, insert_data)
                
                # æ›´æ–°æ•°æ®çŠ¶æ€
                cursor.execute("""
                    INSERT OR REPLACE INTO data_status 
                    (code, last_updated, record_count, status)
                    VALUES (?, ?, ?, ?)
                """, (data["code"], datetime.now().isoformat(), 1, "success"))
            
            conn.commit()
            conn.close()
            print(f"âœ… æˆåŠŸä¿å­˜ {len(stock_data_list)} æ¡è®°å½•åˆ°æ•°æ®åº“")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")

async def crawl_multiple_stocks(stock_codes: List[str], target_date: str = None, db_path: str = None):
    """æ‰¹é‡çˆ¬å–å¤šä¸ªè‚¡ç¥¨"""
    crawler = TencentStockCrawler(db_path)
    
    try:
        results = []
        for i, stock_code in enumerate(stock_codes):
            print(f"\n--- å¤„ç†ç¬¬ {i+1}/{len(stock_codes)} åªè‚¡ç¥¨ ---")
            data = await crawler.crawl_stock_price(stock_code, target_date)
            if data:
                results.append(data)
            
            # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            if i < len(stock_codes) - 1:
                await asyncio.sleep(0.5)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        if results and db_path:
            crawler.save_to_database(results)
        
        print(f"\nğŸ“Š çˆ¬å–ç»“æœæ±‡æ€»:")
        print(f"æˆåŠŸçˆ¬å–: {len(results)} åªè‚¡ç¥¨")
        for result in results:
            change_info = ""
            if result.get("change") is not None:
                change_info = f" (æ¶¨è·Œ: {result['change']:+.2f}, {result['change_percent']:+.2f}%)"
            print(f"- {result['code']} ({result['name']}): {result['close']:.2f} å…ƒ{change_info}")
            
        return len(results)
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡çˆ¬å–å¤±è´¥: {e}")
        return 0

async def main():
    """ä¸»å‡½æ•° - æµ‹è¯•æ¨¡å¼"""
    # æ•°æ®åº“è·¯å¾„ï¼ˆå¦‚æœéœ€è¦ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
    db_path = "/Users/riching/work/hywork/db/sqlite/full_a_stock_cache.db"
    
    # æµ‹è¯•è‚¡ç¥¨ä»£ç 
    test_stocks = ["600519", "000001", "002323", "000858", "600036"]
    
    # ç›®æ ‡æ—¥æœŸï¼ˆå¯é€‰ï¼‰
    target_date = "2026-02-09"
    
    success_count = await crawl_multiple_stocks(test_stocks, target_date, db_path)
    
    if success_count > 0:
        print(f"\nğŸ‰ æˆåŠŸçˆ¬å– {success_count} åªè‚¡ç¥¨çš„ä»·æ ¼æ•°æ®ï¼")
        return True
    else:
        print(f"\nâŒ æœªèƒ½æˆåŠŸçˆ¬å–ä»»ä½•è‚¡ç¥¨æ•°æ®")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
