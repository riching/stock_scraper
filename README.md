# è‚¡ç¥¨æ•°æ®çˆ¬è™«ç³»ç»Ÿ

ä¸€ä¸ªåŸºäºå¤šçº¿ç¨‹ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¶æ„çš„é«˜æ€§èƒ½è‚¡ç¥¨æ•°æ®çˆ¬è™«ç³»ç»Ÿï¼Œæ”¯æŒ6ä¸ªä¸»æµæ•°æ®æºçš„å®æ—¶å’Œå†å²æ•°æ®é‡‡é›†ã€‚

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

### å¤šçº¿ç¨‹ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¶æ„
- 6ä¸ªæ¶ˆè´¹è€…çº¿ç¨‹å¹¶å‘è¿è¡Œï¼Œå¤§å¹…æå‡çˆ¬å–æ•ˆç‡
- çº¿ç¨‹å®‰å…¨çš„ç»Ÿè®¡ä¿¡æ¯ç®¡ç†
- é˜Ÿåˆ—ä»»åŠ¡åˆ†é…æœºåˆ¶ï¼Œç¡®ä¿è´Ÿè½½å‡è¡¡
- ä¼˜é›…çš„çº¿ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†å’Œé”™è¯¯å¤„ç†

### å¤šæ•°æ®æºæ”¯æŒ
- **æ–°æµªè´¢ç»**ï¼šæ”¯æŒå†å²æ•°æ®çˆ¬å–ï¼Œè¦†ç›–Aè‚¡å¸‚åœº
- **è…¾è®¯è´¢ç»**ï¼šæ”¯æŒå®æ—¶å’Œå†å²æ•°æ®ï¼Œæ•°æ®æ›´æ–°åŠæ—¶
- **ä¸œæ–¹è´¢å¯Œ**ï¼šæ”¯æŒå®æ—¶æ•°æ®ï¼Œæ•°æ®è´¨é‡é«˜
- **Akshare**ï¼šé«˜è´¨é‡é‡‘èæ•°æ®æ¥å£
- **Baostock**ï¼šä¸“ä¸šé‡‘èæ•°æ®å¹³å°
- **Yahoo Finance**ï¼šå›½é™…æ•°æ®æºï¼Œæ”¯æŒå…¨çƒå¸‚åœº

### æ•°æ®å¤„ç†èƒ½åŠ›
- å®æ—¶æ•°æ®å’Œå†å²æ•°æ®åŒæ¨¡å¼æ”¯æŒ
- æ•°æ®éªŒè¯å’Œå¯¹æ¯”åŠŸèƒ½
- è‡ªåŠ¨å»é‡å’Œæ•°æ®æ¸…æ´—
- æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼ˆMAã€RSIç­‰ï¼‰
- æƒ…æ„Ÿåˆ†æå’ŒLLMæ™ºèƒ½åˆ†æ

## ğŸ“ é¡¹ç›®ç»“æ„

```
stock_scraper/
â”œâ”€â”€ crawler/                    # çˆ¬è™«æ¨¡å—
â”‚   â”œâ”€â”€ multi_source_crawler.py         # å¤šçº¿ç¨‹å®æ—¶æ•°æ®çˆ¬è™«
â”‚   â”œâ”€â”€ multi_source_history_crawler.py  # å¤šçº¿ç¨‹å†å²æ•°æ®çˆ¬è™«
â”‚   â”œâ”€â”€ sina/                          # æ–°æµªè´¢ç»çˆ¬è™«
â”‚   â”œâ”€â”€ tencent/                       # è…¾è®¯è´¢ç»çˆ¬è™«
â”‚   â”œâ”€â”€ eastmoney/                     # ä¸œæ–¹è´¢å¯Œçˆ¬è™«
â”‚   â”œâ”€â”€ baostock/                      # Baostockçˆ¬è™«
â”‚   â””â”€â”€ yahoo_finance/                 # Yahoo Financeçˆ¬è™«
â”œâ”€â”€ utils/                      # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ stock_database.py              # æ•°æ®åº“æ“ä½œ
â”‚   â”œâ”€â”€ akshare_data.py               # Akshareæ•°æ®æ¥å£
â”‚   â”œâ”€â”€ data_saver.py                 # æ•°æ®ä¿å­˜
â”‚   â”œâ”€â”€ deduplication.py              # æ•°æ®å»é‡
â”‚   â”œâ”€â”€ sentiment_calculator.py        # æƒ…æ„Ÿåˆ†æ
â”‚   â””â”€â”€ llm_analyzer.py              # LLMåˆ†æ
â”œâ”€â”€ app/                        # Webåº”ç”¨
â”‚   â”œâ”€â”€ main.py                       # Flaskåº”ç”¨ä¸»ç¨‹åº
â”‚   â”œâ”€â”€ models/                       # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ templates/                    # HTMLæ¨¡æ¿
â”‚   â””â”€â”€ static/                      # é™æ€èµ„æº
â”œâ”€â”€ config/                     # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ settings.py                  # é…ç½®ç®¡ç†
â”œâ”€â”€ requirements.txt            # Pythonä¾èµ–
â””â”€â”€ README.md                  # é¡¹ç›®è¯´æ˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚
- Python 3.8+
- SQLite 3
- ä¾èµ–åº“ï¼šè§ requirements.txt

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### é…ç½®æ•°æ®åº“

ç¼–è¾‘ `config/settings.py`ï¼Œé…ç½®æ•°æ®åº“è·¯å¾„ï¼š

```python
DATABASE_PATH = "/path/to/your/database.db"
```

### è¿è¡Œçˆ¬è™«

#### å®æ—¶æ•°æ®çˆ¬å–ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰

```bash
python crawler/multi_source_crawler.py
```

#### å†å²æ•°æ®çˆ¬å–

```bash
python crawler/multi_source_history_crawler.py
```

#### å¯åŠ¨Webåº”ç”¨

```bash
python app/main.py
```

è®¿é—® http://localhost:5000

## ğŸ“Š æ•°æ®åº“Schema

è¯¦ç»†çš„æ•°æ®åº“è¡¨ç»“æ„è¯·å‚è€ƒ [DATABASE_SCHEMA.md](DATABASE_SCHEMA.md)

### ä¸»è¦æ•°æ®è¡¨

- **stock_list**: è‚¡ç¥¨åˆ—è¡¨
- **merged_stocks**: åˆå¹¶çš„è‚¡ç¥¨æ•°æ®
- **data_status**: æ•°æ®çŠ¶æ€è·Ÿè¸ª
- **stock_news**: è‚¡ç¥¨æ–°é—»
- **stock_announcements**: å…¬å‘Šä¿¡æ¯
- **stock_comments**: è¯„è®ºæ•°æ®
- **analyst_reports**: åˆ†æå¸ˆæŠ¥å‘Š
- **stock_sentiment_scores**: æƒ…æ„Ÿè¯„åˆ†
- **stock_classifications**: è‚¡ç¥¨åˆ†ç±»

## ğŸ”§ é…ç½®è¯´æ˜

### çˆ¬è™«é…ç½®

```python
# æœ€å¤§è°ƒç”¨æ¬¡æ•°é™åˆ¶
MAX_CALLS = 5000

# æµ‹è¯•æ¨¡å¼
TEST_MODE = True

# ç›®æ ‡æ—¥æœŸ
TARGET_DATE = "2026-02-13"
```

### æ•°æ®æºé…ç½®

æ¯ä¸ªæ•°æ®æºéƒ½æœ‰ç‹¬ç«‹çš„é…ç½®é€‰é¡¹ï¼Œå¯ä»¥åœ¨å¯¹åº”çš„çˆ¬è™«æ–‡ä»¶ä¸­ä¿®æ”¹ã€‚

## ğŸ“ˆ æ€§èƒ½ç‰¹ç‚¹

- **å¹¶å‘å¤„ç†**ï¼š6ä¸ªçº¿ç¨‹åŒæ—¶å·¥ä½œï¼Œå¤§å¹…æå‡æ•ˆç‡
- **æ™ºèƒ½é‡è¯•**ï¼šå¤±è´¥è‡ªåŠ¨é‡è¯•æœºåˆ¶
- **æ•°æ®éªŒè¯**ï¼šå¤šç»´åº¦æ•°æ®è´¨é‡æ£€æŸ¥
- **å†…å­˜ä¼˜åŒ–**ï¼šæµå¼å¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º
- **é”™è¯¯æ¢å¤**ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„æ•°æ®æº

1. åœ¨ `crawler/` ä¸‹åˆ›å»ºæ–°çš„æ•°æ®æºç›®å½•
2. å®ç°çˆ¬è™«ç±»ï¼Œç»§æ‰¿ `BaseWorker`
3. åœ¨ `multi_source_crawler.py` ä¸­æ³¨å†Œæ–°çš„Worker
4. æµ‹è¯•æ•°æ®è´¨é‡å’Œæ€§èƒ½

### è‡ªå®šä¹‰æ•°æ®å¤„ç†

ä¿®æ”¹ `utils/` ä¸‹çš„å·¥å…·ç±»ï¼Œå®ç°è‡ªå®šä¹‰çš„æ•°æ®å¤„ç†é€»è¾‘ã€‚

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### çˆ¬å–æŒ‡å®šè‚¡ç¥¨æ•°æ®

```python
from crawler.multi_source_crawler import MultiSourceRealTimeCrawler

crawler = MultiSourceRealTimeCrawler(
    db_path="/path/to/database.db",
    test_mode=False
)

# çˆ¬å–æŒ‡å®šè‚¡ç¥¨
stocks = ["000001", "600519", "000858"]
stats = crawler.crawl(stocks, "2026-02-13")

print(f"æˆåŠŸ: {stats['success']}, å¤±è´¥: {stats['failure']}")
```

### æŸ¥è¯¢æ•°æ®åº“

```python
from utils.stock_database import StockDatabase

with StockDatabase("/path/to/database.db") as db:
    # è·å–è‚¡ç¥¨æ•°æ®
    data = db.get_stock_data("000001", "2026-02-13")
    print(data)
    
    # è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
    codes = db.get_all_stock_codes()
    print(f"å…±æœ‰ {len(codes)} åªè‚¡ç¥¨")
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ“„ License

MIT License

## ğŸ“ è”ç³»æ–¹å¼

- GitHub: https://github.com/riching/stock_scraper
- Issues: https://github.com/riching/stock_scraper/issues

## ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰å¼€æºæ•°æ®æºå’Œå·¥å…·çš„æ”¯æŒï¼

---

**æ³¨æ„**ï¼šæœ¬ç³»ç»Ÿä»…ç”¨äºå­¦ä¹ å’Œç ”ç©¶ç›®çš„ï¼Œè¯·éµå®ˆç›¸å…³æ•°æ®æºçš„ä½¿ç”¨æ¡æ¬¾å’Œæ³•å¾‹æ³•è§„ã€‚
